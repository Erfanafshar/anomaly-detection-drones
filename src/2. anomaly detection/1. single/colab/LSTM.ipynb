{"cells":[{"cell_type":"markdown","source":["LSTM v2.6 (seperate attacks, simplify normalization)"],"metadata":{"id":"CYO8vAeurVHq"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","import time\n","\n","# parameters\n","num_features = 10\n","num_scenarios = 12\n","scenario_length = 1000\n","attack_type = 0 \t\t# 0: all, 1: DoS, 2: FDI, 3: Replay\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 32\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1 data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data['label']\n","data = data.drop(columns=['time', 'label'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized['label'] = labels\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 12)\n","elif attack_type == 1:\n","    scenario_range = range(0, 4)\n","elif attack_type == 2:\n","    scenario_range = range(4, 8)\n","elif attack_type == 3:\n","    scenario_range = range(8, 12)\n","\n","for s in scenario_range:\n","\t\tscenario_start = s * scenario_length\n","\t\tfor i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","\t\t\t\tsequence = data_normalized[i:i + seq_len]\n","\t\t\t\tsequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","model = Sequential()\n","model.add(Input(shape=(seq_len, num_features)))\n","model.add(LSTM(lstm_blocks))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 3.2 model compile\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","# 3.4 model test\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# 3.5 print results\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy:.3f}')\n","print(f'Precision: {precision:.3f}')\n","print(f'Recall: {recall:.3f}')\n","print(f'F1-score: {f1:.3f}')\n","\n","# 3.6 print training time\n","training_time = end_time - start_time\n","print(f\"Training Time: {training_time:.1f}\")\n"],"metadata":{"id":"RUw_JxYvXQxR","collapsed":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LSTM v2.7 (seperate scenario for train & test!)"],"metadata":{"id":"qm3MUIYPAOga"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Bidirectional, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","import time\n","\n","# parameters\n","num_features = 10\n","num_scenarios = 12\n","scenario_length = 1000\n","attack_type = 0 \t\t# 0: all, 1: DoS, 2: FDI, 3: Replay\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 32\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1 data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data['label']\n","data = data.drop(columns=['time', 'label'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized['label'] = labels\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 12)\n","elif attack_type == 1:\n","    scenario_range = range(0, 4)\n","elif attack_type == 2:\n","    scenario_range = range(4, 8)\n","elif attack_type == 3:\n","    scenario_range = range(8, 12)\n","\n","# train data\n","for s in [0, 1, 2, 4, 5, 6, 8, 9, 10]:\n","\t\tscenario_start = s * scenario_length\n","\t\tfor i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","\t\t\t\tsequence = data_normalized[i:i + seq_len]\n","\t\t\t\tsequences.append(sequence)\n","X_train = array(sequences)\n","\n","sequences = []\n","\n","# test data\n","for s in [3, 7, 11]:\n","\t\tscenario_start = s * scenario_length\n","\t\tfor i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","\t\t\t\tsequence = data_normalized[i:i + seq_len]\n","\t\t\t\tsequences.append(sequence)\n","X_test = array(sequences)\n","\n","\n","# 2.2 reshape data for LSTM network\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","model = Sequential()\n","model.add(Input(shape=(seq_len, num_features)))\n","model.add(LSTM(lstm_blocks))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 3.2 model compile\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","# 3.4 model test\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# 3.5 print results\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy:.3f}')\n","print(f'Precision: {precision:.3f}')\n","print(f'Recall: {recall:.3f}')\n","print(f'F1-score: {f1:.3f}')\n","\n","# 3.6 print training time\n","training_time = end_time - start_time\n","print(f\"Training Time: {training_time:.1f}\")\n"],"metadata":{"id":"q6DJu3OCAUPQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8sKtkcT4XQxM"},"source":["LSTM v2.5 (add preprocessing, code organizing)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","\n","# parameters\n","num_features = 10\n","num_scenarios = 12\n","scenario_length = 1000\n","\n","# hyper-parameter\n","seq_len = 1\n","seq_overlap = 0\n","lstm_blocks = 64\n","epoch_val = 20\n","batch_size_val = 4\n","data_normalization = 1\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","if data_normalization == 0:\n","\tdata = data.drop(columns=['time'])\n","\tdata_normalized = data\n","else:\n","\tlabels = data['label']\n","\tdata = data.drop(columns=['time', 'label'])\n","\n","\tif data_normalization == 1:\n","\t\tscaler = StandardScaler()\n","\telif data_normalization == 2:\n","\t\tscaler = MinMaxScaler()\n","\n","\tdata_normalized = scaler.fit_transform(data)\n","\tdata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","\tdata_normalized['label'] = labels\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","for s in range(num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","model = Sequential()\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# 3.2 model compile\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# 3.5 print results\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy:.3f}')\n","print(f'Precision: {precision:.3f}')\n","print(f'Recall: {recall:.3f}')\n","print(f'F1-score: {f1:.3f}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718300155696,"user_tz":240,"elapsed":212058,"user":{"displayName":"Erfan Afshar","userId":"16269818549890829749"}},"outputId":"d3b1df94-a275-4be7-83f0-9d21d3de9901","collapsed":true,"id":"OX_cHMkurnWv"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm (LSTM)                 (None, 64)                19200     \n","                                                                 \n"," dense (Dense)               (None, 1)                 65        \n","                                                                 \n","=================================================================\n","Total params: 19265 (75.25 KB)\n","Trainable params: 19265 (75.25 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","2248/2248 [==============================] - 10s 4ms/step - loss: 0.4380 - accuracy: 0.8435\n","Epoch 2/20\n","2248/2248 [==============================] - 10s 5ms/step - loss: 0.4152 - accuracy: 0.8468\n","Epoch 3/20\n","2248/2248 [==============================] - 6s 3ms/step - loss: 0.4085 - accuracy: 0.8466\n","Epoch 4/20\n","2248/2248 [==============================] - 8s 4ms/step - loss: 0.4012 - accuracy: 0.8466\n","Epoch 5/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3930 - accuracy: 0.8478\n","Epoch 6/20\n","2248/2248 [==============================] - 8s 3ms/step - loss: 0.3857 - accuracy: 0.8497\n","Epoch 7/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3776 - accuracy: 0.8505\n","Epoch 8/20\n","2248/2248 [==============================] - 9s 4ms/step - loss: 0.3691 - accuracy: 0.8545\n","Epoch 9/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3612 - accuracy: 0.8590\n","Epoch 10/20\n","2248/2248 [==============================] - 8s 4ms/step - loss: 0.3543 - accuracy: 0.8606\n","Epoch 11/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3468 - accuracy: 0.8652\n","Epoch 12/20\n","2248/2248 [==============================] - 9s 4ms/step - loss: 0.3398 - accuracy: 0.8683\n","Epoch 13/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3331 - accuracy: 0.8689\n","Epoch 14/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3276 - accuracy: 0.8727\n","Epoch 15/20\n","2248/2248 [==============================] - 9s 4ms/step - loss: 0.3206 - accuracy: 0.8752\n","Epoch 16/20\n","2248/2248 [==============================] - 6s 3ms/step - loss: 0.3152 - accuracy: 0.8775\n","Epoch 17/20\n","2248/2248 [==============================] - 8s 4ms/step - loss: 0.3090 - accuracy: 0.8811\n","Epoch 18/20\n","2248/2248 [==============================] - 7s 3ms/step - loss: 0.3054 - accuracy: 0.8804\n","Epoch 19/20\n","2248/2248 [==============================] - 8s 4ms/step - loss: 0.2997 - accuracy: 0.8829\n","Epoch 20/20\n","2248/2248 [==============================] - 8s 4ms/step - loss: 0.2946 - accuracy: 0.8844\n","94/94 [==============================] - 1s 2ms/step\n","Accuracy: 0.884\n","Precision: 0.736\n","Recall: 0.282\n","F1-score: 0.407\n"]}]},{"cell_type":"markdown","metadata":{"id":"TO6gVm4Oxv81"},"source":["LSTM v2.4 (add 1d-CNN) (not working)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.layers import Conv1D\n","from tensorflow.keras.layers import MaxPooling1D\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","num_features = 10\n","\n","seq_len = 40\n","lstm_blocks = 20\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# load\n","train_data = pd.read_csv('dataset_train.csv')\n","test_data = pd.read_csv('dataset_test.csv')\n","\n","# drop time\n","train_data = train_data.drop(columns=['time'])\n","test_data = test_data.drop(columns=['time'])\n","\n","# split into samples\n","samples = list()\n","\n","for i in range(0,1000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(1000,2000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(2000,3000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","for i in range(0,1000-seq_len):\n","\tsample = test_data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","\n","data = array(samples)\n","data_reshaped = data.reshape(data.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data.shape[1], data.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data.shape[1], data.shape[2])\n","\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# Build the LSTM model\n","model = Sequential()\n","# model.add(Conv1D(filters=8, kernel_size=4, padding='same', activation='relu'))\n","# model.add(MaxPooling1D(pool_size=2))\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1-score: {f1}')"],"metadata":{"id":"UeXcR5kQxv81"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NS1dWEW7v-0Q"},"source":["LSTM v2.3 (add dropout)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from tensorflow.keras.layers import Dropout\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","num_features = 10\n","\n","seq_len = 40\n","lstm_blocks = 20\n","epoch_val = 20\n","batch_size_val = 4\n","\n","dropout_ver = 2\n","\n","# load\n","train_data = pd.read_csv('dataset_train.csv')\n","test_data = pd.read_csv('dataset_test.csv')\n","\n","# drop time\n","train_data = train_data.drop(columns=['time'])\n","test_data = test_data.drop(columns=['time'])\n","\n","# split into samples\n","samples = list()\n","\n","for i in range(0,1000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(1000,2000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(2000,3000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","for i in range(0,1000-seq_len):\n","\tsample = test_data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","\n","data = array(samples)\n","data_reshaped = data.reshape(data.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data.shape[1], data.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data.shape[1], data.shape[2])\n","\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# Build the LSTM model\n","if dropout_ver == 1:\n","\tmodel = Sequential()\n","\tmodel.add(LSTM(lstm_blocks, dropout=0.2, recurrent_dropout=0.2, input_shape=(seq_len, num_features)))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","elif dropout_ver == 2:\n","\tmodel = Sequential()\n","\tmodel.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","\tmodel.add(Dropout(0.2))\n","\tmodel.add(Dense(1, activation='sigmoid'))\n","\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1-score: {f1}')"],"metadata":{"id":"_Uxzk7jDv-0U"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"S0uBYykzDoZq"},"source":["LSTM v2.2 (split all data into train and test randomly)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","num_features = 10\n","\n","seq_len = 40\n","lstm_blocks = 20\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# load\n","data = pd.read_csv('dataset.csv')\n","\n","# drop time\n","data = data.drop(columns=['time'])\n","\n","# split into samples\n","samples = list()\n","\n","for i in range(0,1000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(1000,2000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(2000,3000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(0,3000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","\n","data = array(samples)\n","data_reshaped = data.reshape(data.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data.shape[1], data.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data.shape[1], data.shape[2])\n","\n","y_train = X_train[:, -1, -1]\n","y_test = X_test[:, -1, -1]\n","X_train = X_train[:, :, :-1]\n","X_test = X_test[:, :, :-1]\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","print(f'F1-score: {f1}')"],"metadata":{"id":"E7j7fzfZDcop","colab":{"base_uri":"https://localhost:8080/"},"outputId":"d387b595-f135-45e0-ccf9-5129b689532b","collapsed":true},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," lstm_1 (LSTM)               (None, 20)                2480      \n","                                                                 \n"," dense_1 (Dense)             (None, 1)                 21        \n","                                                                 \n","=================================================================\n","Total params: 2501 (9.77 KB)\n","Trainable params: 2501 (9.77 KB)\n","Non-trainable params: 0 (0.00 Byte)\n","_________________________________________________________________\n","None\n","Epoch 1/20\n","1095/1095 [==============================] - 14s 11ms/step - loss: 0.4892 - accuracy: 0.7950\n","Epoch 2/20\n","1095/1095 [==============================] - 12s 11ms/step - loss: 0.4399 - accuracy: 0.8023\n","Epoch 3/20\n"," 159/1095 [===>..........................] - ETA: 9s - loss: 0.3918 - accuracy: 0.8082"]}]},{"cell_type":"markdown","metadata":{"id":"roetxnyVDjPV"},"source":["LSTM v2.1 (change dataset files)"]},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","# n = 4000\n","num_features = 10;\n","\n","seq_len = 5\n","lstm_blocks = 50;\n","epoch = 20;\n","batch_sizee = 4;\n","\n","# load\n","train_data = pd.read_csv('dataset_train.csv')\n","test_data = pd.read_csv('dataset_test.csv')\n","\n","# drop time\n","train_data = train_data.drop(columns=['time'])\n","test_data = test_data.drop(columns=['time'])\n","\n","# split into samples\n","samples_train = list()\n","samples_test = list()\n","\n","for i in range(0,1000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples_train.append(sample)\n","for i in range(1000,2000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples_train.append(sample)\n","for i in range(2000,3000-seq_len):\n","\tsample = train_data[i:i+seq_len]\n","\tsamples_train.append(sample)\n","\n","for i in range(0,1000-seq_len):\n","\tsample = test_data[i:i+seq_len]\n","\tsamples_test.append(sample)\n","\n","# reshape subsequences\n","train_data = array(samples_train)\n","test_data = array(samples_test)\n","\n","X_train = train_data[:, :, :num_features]\n","X_test = test_data[:, :, :num_features]\n","y_train = train_data[:, -1, -1]\n","y_test = test_data[:, -1, -1]\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=epoch, batch_size=batch_sizee)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","# print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","# print(f'F1-score: {f1}')"],"metadata":{"id":"iIqPw1zF0S7N"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["LSTM v2 (appropraite sequence generation)"],"metadata":{"id":"ezz2ivHP3NCa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"IvSYvt0BThZV"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","n = 4000\n","num_features = 10;\n","\n","seq_len = 5\n","split_index = 3400;\n","lstm_blocks = 50;\n","epoch = 20;\n","batch_sizee = 4;\n","\n","# load\n","data = pd.read_csv('dataset.csv')\n","# drop time\n","data = data.drop(columns=['time'])\n","\n","# split into samples\n","samples = list()\n","for i in range(0,1000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(1000,2000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(2000,3000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","for i in range(3000,4000-seq_len):\n","\tsample = data[i:i+seq_len]\n","\tsamples.append(sample)\n","\n","# reshape subsequences\n","data = array(samples)\n","\n","X_train = data[:split_index, :, :num_features]\n","X_test = data[split_index:, :, :num_features]\n","y_train = data[:split_index, -1, -1]\n","y_test = data[split_index:, -1, -1]\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","model.fit(X_train, y_train, epochs=epoch, batch_size=batch_sizee)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int).reshape(-1)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred)\n","recall = recall_score(y_test, y_pred)\n","f1 = f1_score(y_test, y_pred)\n","\n","# print(f'Accuracy: {accuracy}')\n","print(f'Precision: {precision}')\n","print(f'Recall: {recall}')\n","# print(f'F1-score: {f1}')\n","\n"]},{"cell_type":"markdown","source":["X_train shape: (3000, 5, 10)\n","X_test shape: (980, 5, 10)\n","y_train shape: (3000,)\n","y_test shape: (980,)"],"metadata":{"id":"482dpFSnKZ1v"}},{"cell_type":"markdown","metadata":{"id":"YilunyaFTex6"},"source":["LSTM v1 (basic)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1M5CAYn5tRmX"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","\n","\n","# Load the dataset\n","data = pd.read_csv('dataset.csv')\n","num_data, num_features = data.shape\n","num_features = num_features - 1\n","split_index = int(num_data * 0.8)\n","\n","# Split the data into training and test sets\n","X_train = data.iloc[:split_index, :-1]\n","y_train = data.iloc[:split_index, -1]\n","X_test = data.iloc[split_index:, :-1]\n","y_test = data.iloc[split_index:, -1]\n","\n","# Build the LSTM model\n","model = Sequential()\n","model.add(LSTM(20, input_shape=(1, num_features)))\n","model.add(Dense(1, activation='sigmoid'))\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","\n","X_train = X_train.to_numpy().reshape(32, 1, num_features)\n","y_train = y_train.to_numpy().reshape(32, 1, 1)\n","X_test = X_test.to_numpy().reshape(12, 1, num_features)\n","y_test = y_test.to_numpy().reshape(12, 1, 1)\n","\n","# Train the LSTM model\n","model.fit(X_train, y_train, epochs=10, batch_size=32)\n","\n","# Make predictions on the test set\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","# Calculate the accuracy of the model\n","accuracy = accuracy_score(y_test, y_pred)\n","print(f'Accuracy: {accuracy}')"]}],"metadata":{"colab":{"provenance":[],"toc_visible":true,"authorship_tag":"ABX9TyMmzAfeNYPwTluqCmTH2zuB"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}