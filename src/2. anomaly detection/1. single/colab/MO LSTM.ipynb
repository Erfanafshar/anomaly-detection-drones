{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPrXeupwcj2+aNX1FNMB2I7"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["multi output LSTM (single) v1.2 (fix for automatic dataset, change of loss functions)"],"metadata":{"id":"22tsN8ap0MP3"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.keras.utils import to_categorical\n","import time\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","# parameters\n","num_features = 10\n","scenario_length = 1000\n","num_attack_types = 3 + 1\n","num_attack_targets = 10 + 1\n","\n","num_scenarios = 50\n","\n","# hyper-parameter\n","seq_len = 40\n","seq_overlap = seq_len - 1\n","lstm_blocks = 128\n","epoch_val = 100\n","batch_size_val = 128\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label', 'type', 'target']]\n","data = data.drop(columns=['time', 'label', 'type', 'target'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2. data preparation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network & label sequences\n","y_train_detection = X_train[:, -1, -3]\n","y_train_identification = X_train[:, -1, -2]\n","y_train_isolation = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-3]\n","\n","y_test_detection = X_test[:, -1, -3]\n","y_test_identification = X_test[:, -1, -2]\n","y_test_isolation = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-3]\n","\n","# convert to one-hot encoding\n","y_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\n","y_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\n","y_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\n","y_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n","\n","# 3. model creation\n","input_layer = Input(shape=(seq_len, num_features))\n","shared_lstm = LSTM(lstm_blocks)(input_layer)\n","output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n","output_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\n","output_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n","\n","model = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output': 'binary_crossentropy',\n","        'identification_output': 'kl_divergence',\n","        'isolation_output': 'kl_divergence'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output': ['accuracy'],\n","        'identification_output': ['accuracy'],\n","        'isolation_output': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","# 3.4 model test\n","y_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\n","y_pred_identification = np.argmax(y_pred_identification, axis=1)\n","y_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n","\n","# convert from one-hot encode to classes\n","y_test_identification = np.argmax(y_test_identification, axis=1)\n","y_test_isolation = np.argmax(y_test_isolation, axis=1)\n","\n","# 3.5 print results for detection\n","accuracy_det = accuracy_score(y_test_detection, y_pred_detection)\n","precision_det = precision_score(y_test_detection, y_pred_detection)\n","recall_det = recall_score(y_test_detection, y_pred_detection)\n","f1_det = f1_score(y_test_detection, y_pred_detection)\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n","\n","# 3.8 print training time\n","training_time = end_time - start_time\n","\n","# print section\n","print(f'Detection - Accuracy: {accuracy_det:.3f}')\n","print(f'Detection - Precision: {precision_det:.3f}')\n","print(f'Detection - Recall: {recall_det:.3f}')\n","print(f'Detection - F1-score: {f1_det:.3f}')\n","\n","print(f\"Training Time: {training_time:.1f}\")\n","\n","print(f'Identification - Accuracy: {accuracy_id:.3f}')\n","print(f'Isolation - Accuracy: {accuracy_iso:.3f}')\n","\n","print(classification_report(y_test_detection, y_pred_detection))\n","print(classification_report(y_test_identification, y_pred_identification))\n","print(classification_report(y_test_isolation, y_pred_isolation))"],"metadata":{"id":"XygatgLI0LHa"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["v1.2.3 (plost classification outputs as heatmap)"],"metadata":{"id":"5Zv3Giektx8n"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.keras.utils import to_categorical\n","import time\n","import seaborn as sns\n","import matplotlib.pyplot as plt\n","\n","\n","# parameters\n","num_features = 10\n","scenario_length = 1000\n","num_attack_types = 3 + 1\n","num_attack_targets = 10 + 1\n","\n","num_scenarios = 50\n","\n","# hyper-parameter\n","seq_len = 40\n","seq_overlap = seq_len - 1\n","lstm_blocks = 128\n","epoch_val = 100\n","batch_size_val = 128\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label', 'type', 'target']]\n","data = data.drop(columns=['time', 'label', 'type', 'target'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2. data preparation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network & label sequences\n","y_train_detection = X_train[:, -1, -3]\n","y_train_identification = X_train[:, -1, -2]\n","y_train_isolation = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-3]\n","\n","y_test_detection = X_test[:, -1, -3]\n","y_test_identification = X_test[:, -1, -2]\n","y_test_isolation = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-3]\n","\n","# convert to one-hot encoding\n","y_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\n","y_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\n","y_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\n","y_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n","\n","# 3. model creation\n","input_layer = Input(shape=(seq_len, num_features))\n","shared_lstm = LSTM(lstm_blocks)(input_layer)\n","output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n","output_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\n","output_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n","\n","model = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output': 'binary_crossentropy',\n","        'identification_output': 'kl_divergence',\n","        'isolation_output': 'kl_divergence'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output': ['accuracy'],\n","        'identification_output': ['accuracy'],\n","        'isolation_output': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","# 3.4 model test\n","y_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\n","y_pred_identification = np.argmax(y_pred_identification, axis=1)\n","y_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n","\n","# convert from one-hot encode to classes\n","y_test_identification = np.argmax(y_test_identification, axis=1)\n","y_test_isolation = np.argmax(y_test_isolation, axis=1)\n","\n","# Function to convert classification report to DataFrame\n","def report_to_df(report):\n","    df = pd.DataFrame(report).transpose()\n","    # Remove 'support' if not needed\n","    df = df.drop(columns=['support'], errors='ignore')\n","    return df\n","\n","# Plotting function\n","def plot_and_save_heatmap(df, title, filename):\n","    plt.figure(figsize=(10, 6))\n","    sns.heatmap(df.iloc[:, :], annot=True, cmap='YlGnBu', fmt='.2f')  # Remove 'accuracy' row\n","    plt.title(title)\n","    # plt.savefig(filename, format='png')\n","    plt.show()\n","\n","# Sample classification reports\n","# Assuming y_test and y_pred are already defined\n","report_detection = classification_report(y_test_detection, y_pred_detection, output_dict=True)\n","report_identification = classification_report(y_test_identification, y_pred_identification, output_dict=True)\n","report_isolation = classification_report(y_test_isolation, y_pred_isolation, output_dict=True)\n","\n","# Convert reports to DataFrames\n","df_detection = report_to_df(report_detection)\n","df_identification = report_to_df(report_identification)\n","df_isolation = report_to_df(report_isolation)\n","\n","# Create heatmaps for each report\n","plot_and_save_heatmap(df_detection, \"Detection Report (Binary Classification)\", \"detection_report.png\")\n","plot_and_save_heatmap(df_identification, \"Identification Report (Multi-Class 3 Classes)\", \"identification_report.png\")\n","plot_and_save_heatmap(df_isolation, \"Isolation Report (Multi-Class 10 Classes)\", \"isolation_report.png\")"],"metadata":{"id":"1pBOurYGtyVz"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["multi output LSTM (single) v1.2.2 (add threshold based labeling)(just as epxeriment)"],"metadata":{"id":"Zh9sMYqc72lg"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","from tensorflow.keras.utils import to_categorical\n","import time\n","\n","\n","# parameters\n","num_features = 10\n","scenario_length = 1000\n","num_attack_types = 3 + 1\n","num_attack_targets = 10 + 1\n","\n","num_scenarios = 50\n","\n","# hyper-parameter\n","seq_len = 40\n","seq_overlap = seq_len - 1\n","lstm_blocks = 128\n","epoch_val = 100\n","batch_size_val = 128\n","\n","threshold = 0.1\n","\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label', 'type', 'target']]\n","data = data.drop(columns=['time', 'label', 'type', 'target'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2. data preparation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network & label sequences\n","\n","num_sequences = X_train.shape[0]\n","y_train_detection = np.zeros(num_sequences)\n","y_train_identification = np.zeros(num_sequences)\n","y_train_isolation = np.zeros(num_sequences)\n","\n","for i in range(num_sequences):\n","    attack_count = np.sum(X_train[i, :, -3])\n","    attack_ratio = attack_count / X_train[i].shape[0]\n","    if attack_ratio >= threshold:\n","        first_attack_index = np.where(X_train[i, :, -3] == 1)[0][0]\n","        y_train_detection[i] = 1\n","        y_train_identification[i] = X_train[i, first_attack_index, -2]\n","        y_train_isolation[i] = X_train[i, first_attack_index, -1]\n","\n","X_train = X_train[:, :, :-3]\n","\n","\n","num_sequences = X_test.shape[0]\n","y_test_detection = np.zeros(num_sequences)\n","y_test_identification = np.zeros(num_sequences)\n","y_test_isolation = np.zeros(num_sequences)\n","\n","for i in range(num_sequences):\n","    attack_count = np.sum(X_test[i, :, -3])\n","    attack_ratio = attack_count / X_test[i].shape[0]\n","    if attack_ratio >= threshold:\n","        first_attack_index = np.where(X_test[i, :, -3] == 1)[0][0]\n","        y_test_detection[i] = 1\n","        y_test_identification[i] = X_test[i, first_attack_index, -2]\n","        y_test_isolation[i] = X_test[i, first_attack_index, -1]\n","\n","X_test = X_test[:, :, :-3]\n","\n","# convert to one-hot encoding\n","y_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\n","y_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\n","y_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\n","y_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n","\n","# 3. model creation\n","input_layer = Input(shape=(seq_len, num_features))\n","shared_lstm = LSTM(lstm_blocks)(input_layer)\n","output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n","output_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\n","output_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n","\n","model = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output': 'binary_crossentropy',\n","        'identification_output': 'kl_divergence',\n","        'isolation_output': 'kl_divergence'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output': ['accuracy'],\n","        'identification_output': ['accuracy'],\n","        'isolation_output': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","# 3.4 model test\n","y_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\n","y_pred_identification = np.argmax(y_pred_identification, axis=1)\n","y_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n","\n","# convert from one-hot encode to classes\n","y_test_identification = np.argmax(y_test_identification, axis=1)\n","y_test_isolation = np.argmax(y_test_isolation, axis=1)\n","\n","# 3.5 print results for detection\n","accuracy_det = accuracy_score(y_test_detection, y_pred_detection)\n","precision_det = precision_score(y_test_detection, y_pred_detection)\n","recall_det = recall_score(y_test_detection, y_pred_detection)\n","f1_det = f1_score(y_test_detection, y_pred_detection)\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n","\n","# 3.8 print training time\n","training_time = end_time - start_time\n","\n","\n","# print section\n","print(f'Detection - Accuracy: {accuracy_det:.3f}')\n","print(f'Detection - Precision: {precision_det:.3f}')\n","print(f'Detection - Recall: {recall_det:.3f}')\n","print(f'Detection - F1-score: {f1_det:.3f}')\n","\n","print(f\"Training Time: {training_time:.1f}\")\n","\n","print(f'Identification - Accuracy: {accuracy_id:.3f}')\n","print(f'Isolation - Accuracy: {accuracy_iso:.3f}')\n","\n","print(classification_report(y_test_detection, y_pred_detection))\n","print(classification_report(y_test_identification, y_pred_identification))\n","print(classification_report(y_test_isolation, y_pred_isolation))\n"],"metadata":{"id":"WbxN2Pre71oi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["multi output LSTM (single)"],"metadata":{"id":"4bhBzHRbXP4o"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"MSvizmXTy--l"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler, StandardScaler\n","\n","# parameters\n","num_features = 10\n","num_scenarios = 12\n","scenario_length = 1000\n","attack_type = 0        # 0: all, 1: DoS, 2: FDI, 3: Replay\n","num_attack_types = 3 + 1\n","num_attack_targets = 6 + 1\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 32\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label', 'type', 'target']]\n","data = data.drop(columns=['time', 'label', 'type', 'target'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 12)\n","elif attack_type == 1:\n","    scenario_range = range(0, 4)\n","elif attack_type == 2:\n","    scenario_range = range(4, 8)\n","elif attack_type == 3:\n","    scenario_range = range(8, 12)\n","\n","for s in scenario_range:\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2. data preparation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train_detection = X_train[:, -1, -3]\n","y_train_identification = X_train[:, -1, -2]\n","y_train_isolation = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-3]\n","\n","y_test_detection = X_test[:, -1, -3]\n","y_test_identification = X_test[:, -1, -2]\n","y_test_isolation = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-3]\n","\n","# 3. model creation\n","input_layer = Input(shape=(seq_len, num_features))\n","shared_lstm = LSTM(lstm_blocks)(input_layer)\n","output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n","output_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\n","output_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n","\n","model = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output': 'binary_crossentropy',\n","        'identification_output': 'sparse_categorical_crossentropy',\n","        'isolation_output': 'sparse_categorical_crossentropy'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output': ['accuracy'],\n","        'identification_output': ['accuracy'],\n","        'isolation_output': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\n","y_pred_identification = np.argmax(y_pred_identification, axis=1)\n","y_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n","\n","# 3.5 print results for detection\n","accuracy_det = accuracy_score(y_test_detection, y_pred_detection)\n","precision_det = precision_score(y_test_detection, y_pred_detection)\n","recall_det = recall_score(y_test_detection, y_pred_detection)\n","f1_det = f1_score(y_test_detection, y_pred_detection)\n","\n","print(f'Detection - Accuracy: {accuracy_det:.3f}')\n","print(f'Detection - Precision: {precision_det:.3f}')\n","print(f'Detection - Recall: {recall_det:.3f}')\n","print(f'Detection - F1-score: {f1_det:.3f}')\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n","print(f'Identification - Accuracy: {accuracy_id:.3f}')\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n","print(f'Localization - Accuracy: {accuracy_iso:.3f}')\n"]}]}