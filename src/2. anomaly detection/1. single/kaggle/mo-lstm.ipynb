{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9509881,"sourceType":"datasetVersion","datasetId":5788529}],"dockerImageVersionId":30775,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"v1.4 MO LSTM (detection time calculation)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom tensorflow.keras.utils import to_categorical\nimport time\nimport random\nimport tensorflow as tf\n\n\n# parameters\nnum_features = 10\nscenario_length = 1000\nnum_attack_types = 3 + 1\nnum_attack_targets = 10 + 1\n\nnum_scenarios = 50\n\n# hyper-parameter\nseq_len = 40\nseq_overlap = seq_len - 1\nlstm_blocks = 128\nepoch_val = 5\nbatch_size_val = 128\n\n# 1. data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-single-quadcopter/dataset.csv')\n\n# 1.1 normalization\nlabels = data[['label', 'type', 'target']]\ndata = data.drop(columns=['time', 'label', 'type', 'target'])\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2. data preparation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n# 2.2 reshape data for LSTM network & label sequences\ny_train_detection = X_train[:, -1, -3]\ny_train_identification = X_train[:, -1, -2]\ny_train_isolation = X_train[:, -1, -1]\nX_train = X_train[:, :, :-3]\n\ny_test_detection = X_test[:, -1, -3]\ny_test_identification = X_test[:, -1, -2]\ny_test_isolation = X_test[:, -1, -1]\nX_test = X_test[:, :, :-3]\n\n# convert to one-hot encoding\ny_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\ny_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\ny_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\ny_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n\n# 3. model creation\ninput_layer = Input(shape=(seq_len, num_features))\nshared_lstm = LSTM(lstm_blocks)(input_layer)\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n\nmodel = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n\n# 3.2 model compile\nmodel.compile(\n    loss={\n        'detection_output': 'binary_crossentropy',\n        'identification_output': 'kl_divergence',\n        'isolation_output': 'kl_divergence'\n    },\n    optimizer='adam',\n    metrics={\n        'detection_output': ['accuracy'],\n        'identification_output': ['accuracy'],\n        'isolation_output': ['accuracy']\n    }\n)\nprint(model.summary())\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n          epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n# 3.4 model test\n# Measure prediction time for 50 random test samples\nprediction_times = []\n\nfor _ in range(50):\n    # Select a random test sample\n    random_idx = random.randint(0, X_test.shape[0] - 1)\n    single_test_sample = X_test[random_idx:random_idx + 1]\n\n    # Measure prediction time for the single sample\n    with tf.device('/CPU:0'):\n        start_prediction_time = time.time()\n        model.predict(single_test_sample)\n        end_prediction_time = time.time()\n\n    # Calculate and store the prediction time\n    prediction_time = end_prediction_time - start_prediction_time\n    prediction_times.append(prediction_time)\n\n# Calculate the average prediction time\naverage_prediction_time = np.mean(prediction_times)\n\n# Print the average prediction time\nprint(f\"Average Real-time Prediction Time (50 Samples, CPU Only): {average_prediction_time:.6f} seconds\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"multi output LSTM (single) v1.3 (add threshold based labeling)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom tensorflow.keras.utils import to_categorical\n\n\n# parameters\nnum_features = 10\nscenario_length = 1000\nnum_attack_types = 3 + 1\nnum_attack_targets = 10 + 1\n\nnum_scenarios = 50\n\n# hyper-parameter\nseq_len = 100\nseq_overlap = seq_len - 1\nlstm_blocks = 512\nepoch_val = 100\nbatch_size_val = 128\n\nthreshold = 0.1\n\n# 1. data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-single-quadcopter/dataset.csv')\n\n# 1.1 normalization\nlabels = data[['label', 'type', 'target']]\ndata = data.drop(columns=['time', 'label', 'type', 'target'])\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2. data preparation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n# 2.2 reshape data for LSTM network & label sequences\n\n\nnum_sequences = X_train.shape[0]\ny_train_detection = np.zeros(num_sequences)\ny_train_identification = np.zeros(num_sequences)\ny_train_isolation = np.zeros(num_sequences)\n\nfor i in range(num_sequences):\n    attack_count = np.sum(X_train[i, :, -3])\n    attack_ratio = attack_count / X_train[i].shape[0]\n    if attack_ratio >= threshold:\n        first_attack_index = np.where(X_train[i, :, -3] == 1)[0][0]\n        y_train_detection[i] = 1\n        y_train_identification[i] = X_train[i, first_attack_index, -2]\n        y_train_isolation[i] = X_train[i, first_attack_index, -1]\n\nX_train = X_train[:, :, :-3]\n\n\nnum_sequences = X_test.shape[0]\ny_test_detection = np.zeros(num_sequences)\ny_test_identification = np.zeros(num_sequences)\ny_test_isolation = np.zeros(num_sequences)\n\nfor i in range(num_sequences):\n    attack_count = np.sum(X_test[i, :, -3])\n    attack_ratio = attack_count / X_test[i].shape[0]\n    if attack_ratio >= threshold:\n        first_attack_index = np.where(X_test[i, :, -3] == 1)[0][0]\n        y_test_detection[i] = 1\n        y_test_identification[i] = X_test[i, first_attack_index, -2]\n        y_test_isolation[i] = X_test[i, first_attack_index, -1]\n\nX_test = X_test[:, :, :-3]\n\n# convert to one-hot encoding\ny_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\ny_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\ny_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\ny_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n\n# 3. model creation\ninput_layer = Input(shape=(seq_len, num_features))\nshared_lstm = LSTM(lstm_blocks)(input_layer)\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n\nmodel = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n\n# 3.2 model compile\nmodel.compile(\n    loss={\n        'detection_output': 'binary_crossentropy',\n        'identification_output': 'kl_divergence',\n        'isolation_output': 'kl_divergence'\n    },\n    optimizer='adam',\n    metrics={\n        'detection_output': ['accuracy'],\n        'identification_output': ['accuracy'],\n        'isolation_output': ['accuracy']\n    }\n)\nprint(model.summary())\n\n# 3.3 model train\nmodel.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n          epochs=epoch_val, batch_size=batch_size_val)\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = np.argmax(y_pred_identification, axis=1)\ny_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n\n# convert from one-hot encode to classes\ny_test_identification = np.argmax(y_test_identification, axis=1)\ny_test_isolation = np.argmax(y_test_isolation, axis=1)\n\n# 3.5 print results for detection\naccuracy_det = accuracy_score(y_test_detection, y_pred_detection)\nprecision_det = precision_score(y_test_detection, y_pred_detection)\nrecall_det = recall_score(y_test_detection, y_pred_detection)\nf1_det = f1_score(y_test_detection, y_pred_detection)\n\n# 3.6 print results for identification\naccuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n\n# 3.7 print results for localization\naccuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n\n# print section\nprint(f'Detection - Accuracy: {accuracy_det:.3f}')\nprint(f'Detection - Precision: {precision_det:.3f}')\nprint(f'Detection - Recall: {recall_det:.3f}')\nprint(f'Detection - F1-score: {f1_det:.3f}')\nprint(f'Identification - Accuracy: {accuracy_id:.3f}')\nprint(f'Isolation - Accuracy: {accuracy_iso:.3f}')\n\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"multi output LSTM (single) v1.2 (fix for automatic dataset, change of loss functions)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom tensorflow.keras.utils import to_categorical\nimport time\n\n\n# parameters\nnum_features = 10\nscenario_length = 1000\nnum_attack_types = 3 + 1\nnum_attack_targets = 10 + 1\n\nnum_scenarios = 50\n\n# hyper-parameter\nseq_len = 100\nseq_overlap = seq_len - 1\nlstm_blocks = 512\nepoch_val = 100\nbatch_size_val = 128\n\n# 1. data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-single-quadcopter/dataset.csv')\n\n# 1.1 normalization\nlabels = data[['label', 'type', 'target']]\ndata = data.drop(columns=['time', 'label', 'type', 'target'])\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2. data preparation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n# 2.2 reshape data for LSTM network & label sequences\ny_train_detection = X_train[:, -1, -3]\ny_train_identification = X_train[:, -1, -2]\ny_train_isolation = X_train[:, -1, -1]\nX_train = X_train[:, :, :-3]\n\ny_test_detection = X_test[:, -1, -3]\ny_test_identification = X_test[:, -1, -2]\ny_test_isolation = X_test[:, -1, -1]\nX_test = X_test[:, :, :-3]\n\n# convert to one-hot encoding\ny_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\ny_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\ny_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\ny_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n\n# 3. model creation\ninput_layer = Input(shape=(seq_len, num_features))\nshared_lstm = LSTM(lstm_blocks)(input_layer)\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n\nmodel = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n\n# 3.2 model compile\nmodel.compile(\n    loss={\n        'detection_output': 'binary_crossentropy',\n        'identification_output': 'kl_divergence',\n        'isolation_output': 'kl_divergence'\n    },\n    optimizer='adam',\n    metrics={\n        'detection_output': ['accuracy'],\n        'identification_output': ['accuracy'],\n        'isolation_output': ['accuracy']\n    }\n)\nprint(model.summary())\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n          epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = np.argmax(y_pred_identification, axis=1)\ny_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n\n# convert from one-hot encode to classes\ny_test_identification = np.argmax(y_test_identification, axis=1)\ny_test_isolation = np.argmax(y_test_isolation, axis=1)\n\n# 3.5 print results for detection\naccuracy_det = accuracy_score(y_test_detection, y_pred_detection)\nprecision_det = precision_score(y_test_detection, y_pred_detection)\nrecall_det = recall_score(y_test_detection, y_pred_detection)\nf1_det = f1_score(y_test_detection, y_pred_detection)\n\n# 3.6 print results for identification\naccuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n\n# 3.7 print results for localization\naccuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n\n# 3.8 print training time\ntraining_time = end_time - start_time\n\n# print section\nprint(f'Detection - Accuracy: {accuracy_det:.3f}')\nprint(f'Detection - Precision: {precision_det:.3f}')\nprint(f'Detection - Recall: {recall_det:.3f}')\nprint(f'Detection - F1-score: {f1_det:.3f}')\n\nprint(f\"Training Time: {training_time:.1f}\")\n\nprint(f'Identification - Accuracy: {accuracy_id:.3f}')\nprint(f'Isolation - Accuracy: {accuracy_iso:.3f}')\n\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v1.4 (different scenarios for train and test)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom tensorflow.keras.utils import to_categorical\n\n\n# parameters\nnum_features = 10\nscenario_length = 1000\nnum_attack_types = 3 + 1\nnum_attack_targets = 10 + 1\n\nnum_scenarios = 50\n\n# hyper-parameter\nseq_len = 40\nseq_overlap = seq_len - 1\nlstm_blocks = \nepoch_val = 100\nbatch_size_val = 128\n\nthreshold = 0.1\n\n# 1. data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-single-quadcopter/dataset.csv')\n\n# 1.1 normalization\nlabels = data[['label', 'type', 'target']]\ndata = data.drop(columns=['time', 'label', 'type', 'target'])\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2. data preparation\n# 2.1 train-test split\ntrain_test_split = 0.75\n\nsplit_index = int(data_sequences.shape[0] * train_test_split)\n\n# Split the data into X_train and X_test\nX_train = data_sequences[:split_index]\nX_test = data_sequences[split_index:]\n\n# Check the shapes\n# print(\"X_train shape:\", X_train.shape)  # Expected: (36750, 20, 13)\n# print(\"X_test shape:\", X_test.shape)    # Expected: (12250, 20, 13)\n\n\n# 2.2 reshape data for LSTM network & label sequences\nnum_sequences = X_train.shape[0]\ny_train_detection = np.zeros(num_sequences)\ny_train_identification = np.zeros(num_sequences)\ny_train_isolation = np.zeros(num_sequences)\n\nfor i in range(num_sequences):\n    attack_count = np.sum(X_train[i, :, -3])\n    attack_ratio = attack_count / X_train[i].shape[0]\n    if attack_ratio >= threshold:\n        first_attack_index = np.where(X_train[i, :, -3] == 1)[0][0]\n        y_train_detection[i] = 1\n        y_train_identification[i] = X_train[i, first_attack_index, -2]\n        y_train_isolation[i] = X_train[i, first_attack_index, -1]\n\nX_train = X_train[:, :, :-3]\n\n\nnum_sequences = X_test.shape[0]\ny_test_detection = np.zeros(num_sequences)\ny_test_identification = np.zeros(num_sequences)\ny_test_isolation = np.zeros(num_sequences)\n\nfor i in range(num_sequences):\n    attack_count = np.sum(X_test[i, :, -3])\n    attack_ratio = attack_count / X_test[i].shape[0]\n    if attack_ratio >= threshold:\n        first_attack_index = np.where(X_test[i, :, -3] == 1)[0][0]\n        y_test_detection[i] = 1\n        y_test_identification[i] = X_test[i, first_attack_index, -2]\n        y_test_isolation[i] = X_test[i, first_attack_index, -1]\n\nX_test = X_test[:, :, :-3]\n\n# convert to one-hot encoding\ny_train_identification = to_categorical(y_train_identification, num_classes=num_attack_types)\ny_test_identification = to_categorical(y_test_identification, num_classes=num_attack_types)\ny_train_isolation = to_categorical(y_train_isolation, num_classes=num_attack_targets)\ny_test_isolation = to_categorical(y_test_isolation, num_classes=num_attack_targets)\n\n# 3. model creation\ninput_layer = Input(shape=(seq_len, num_features))\nshared_lstm = LSTM(lstm_blocks)(input_layer)\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='softmax', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_attack_targets, activation='softmax', name='isolation_output')(shared_lstm)\n\nmodel = Model(inputs=input_layer, outputs=[output_detection, output_identification, output_isolation])\n\n# 3.2 model compile\nmodel.compile(\n    loss={\n        'detection_output': 'binary_crossentropy',\n        'identification_output': 'kl_divergence',\n        'isolation_output': 'kl_divergence'\n    },\n    optimizer='adam',\n    metrics={\n        'detection_output': ['accuracy'],\n        'identification_output': ['accuracy'],\n        'isolation_output': ['accuracy']\n    }\n)\nprint(model.summary())\n\n# 3.3 model train\nmodel.fit(X_train, [y_train_detection, y_train_identification, y_train_isolation],\n          epochs=epoch_val, batch_size=batch_size_val)\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation = model.predict(X_test)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = np.argmax(y_pred_identification, axis=1)\ny_pred_isolation = np.argmax(y_pred_isolation, axis=1)\n\n# convert from one-hot encode to classes\ny_test_identification = np.argmax(y_test_identification, axis=1)\ny_test_isolation = np.argmax(y_test_isolation, axis=1)\n\n# 3.5 print results for detection\naccuracy_det = accuracy_score(y_test_detection, y_pred_detection)\nprecision_det = precision_score(y_test_detection, y_pred_detection)\nrecall_det = recall_score(y_test_detection, y_pred_detection)\nf1_det = f1_score(y_test_detection, y_pred_detection)\n\n# 3.6 print results for identification\naccuracy_id = accuracy_score(y_test_identification, y_pred_identification)\n\n# 3.7 print results for localization\naccuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n\n# print section\nprint(f'Detection - Accuracy: {accuracy_det:.3f}')\nprint(f'Detection - Precision: {precision_det:.3f}')\nprint(f'Detection - Recall: {recall_det:.3f}')\nprint(f'Detection - F1-score: {f1_det:.3f}')\nprint(f'Identification - Accuracy: {accuracy_id:.3f}')\nprint(f'Isolation - Accuracy: {accuracy_iso:.3f}')\n\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}