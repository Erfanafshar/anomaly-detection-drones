{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9570836,"sourceType":"datasetVersion","datasetId":5833752},{"sourceId":9588365,"sourceType":"datasetVersion","datasetId":5847625}],"dockerImageVersionId":30787,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"v3.5 test prediction time","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\nimport random\nimport tensorflow as tf\n\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\nnum_scenarios = 50\n\n# hyper-parameter\nnum_quad = 5\n\ninput_lstm = 64\nshared_lstm = 256\nseq_len = 40\nseq_overlap = seq_len - 1\n\nepoch_val = 5\nbatch_size_val = 128\n\nquad_feature = 10   # 10 for all data, 6 for only sensors\naverage_approach = 'macro'\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-network-of-quadcopters-50k/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\n# Function to create identification vector\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    for col_idx in [51, 54, 57, 60, 62][:num_quad]:\n        if row.iloc[col_idx] > 0:\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n    return attack_types\n\n# Dynamically handle labels and targets based on num_quad\ncols_to_check = [50, 53, 56, 59, 62][:num_quad]  # Select relevant columns\nlabels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\nlabels['type'] = data.apply(create_identification_vector, axis=1)\nlabels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n\n# remove other quads data and old labels\ndata = data.iloc[:, :num_quad * 10]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(num_quad):\n    X_train_heads.append(X_train[:, :, i*10:i*10+quad_feature])\n    X_test_heads.append(X_test[:, :, i*10:i*10+quad_feature])\n\n# 3. Model creation\n# 3.1 Model architecture\ninputs = []\nlstm_layers = []\n\n# Create input and LSTM layers based on num_quad\nfor i in range(num_quad):\n    input_layer = Input(shape=(seq_len, quad_feature))\n    lstm_layer = LSTM(input_lstm, return_sequences=True)(input_layer)\n    inputs.append(input_layer)\n    lstm_layers.append(lstm_layer)\n\n# Shared LSTM layer\nconcat = Concatenate()(lstm_layers)\nshared_lstm = LSTM(shared_lstm)(concat)\n\n# Outputs\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n# Model\nmodel = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train_heads,\n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\n# Measure prediction time for 50 random test samples\nprediction_times = []\n\nfor _ in range(50):\n    # Select a random test sample index\n    random_idx = random.randint(0, X_test_heads[0].shape[0] - 1)\n\n    # Prepare the single test sample for all input heads\n    single_test_sample = [X_test_heads[i][random_idx:random_idx + 1] for i in range(num_quad)]\n\n\n    # Measure prediction time for the single sample\n    with tf.device('/CPU:0'):\n        start_prediction_time = time.time()\n        model.predict(single_test_sample)\n        end_prediction_time = time.time()\n\n    # Calculate and store the prediction time\n    prediction_time = end_prediction_time - start_prediction_time\n    prediction_times.append(prediction_time)\n\n# Calculate the average prediction time\naverage_prediction_time = np.mean(prediction_times)\n\n# Print the average prediction time\nprint(f\"Average Real-time Prediction Time (50 Samples, CPU Only): {average_prediction_time:.6f} seconds\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v3.4 code optimization, output print fixed, can send only sensors data","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\n\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\nnum_scenarios = 50\n\n# hyper-parameter\nnum_quad = 5\n\ninput_lstm = 64\nshared_lstm = 256\nseq_len = 40\nseq_overlap = seq_len - 1\n\nepoch_val = 50\nbatch_size_val = 128\n\nquad_feature = 10   # 10 for all data, 6 for only sensors\naverage_approach = 'macro'\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-network-of-quadcopters-50k/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\n# Function to create identification vector\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    for col_idx in [51, 54, 57, 60, 62][:num_quad]:\n        if row.iloc[col_idx] > 0:\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n    return attack_types\n\n# Dynamically handle labels and targets based on num_quad\ncols_to_check = [50, 53, 56, 59, 62][:num_quad]  # Select relevant columns\nlabels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\nlabels['type'] = data.apply(create_identification_vector, axis=1)\nlabels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n\n# remove other quads data and old labels\ndata = data.iloc[:, :num_quad * 10]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(num_quad):\n    X_train_heads.append(X_train[:, :, i*10:i*10+quad_feature])\n    X_test_heads.append(X_test[:, :, i*10:i*10+quad_feature])\n\n# 3. Model creation\n# 3.1 Model architecture\ninputs = []\nlstm_layers = []\n\n# Create input and LSTM layers based on num_quad\nfor i in range(num_quad):\n    input_layer = Input(shape=(seq_len, quad_feature))\n    lstm_layer = LSTM(input_lstm, return_sequences=True)(input_layer)\n    inputs.append(input_layer)\n    lstm_layers.append(lstm_layer)\n\n# Shared LSTM layer\nconcat = Concatenate()(lstm_layers)\nshared_lstm = LSTM(shared_lstm)(concat)\n\n# Outputs\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n# Model\nmodel = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train_heads,\n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation =\\\nmodel.predict(X_test_heads)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = (y_pred_identification > 0.5).astype(int)\ny_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n\n\n# 3.5 print results for each column\ntraining_time = end_time - start_time\nprint(f\"Training Time: {training_time:.1f}\")\n\n\n# Calculate metrics for detection\naccuracy_det = accuracy_score(y_test_detection, y_pred_detection)\nprecision_det = precision_score(y_test_detection, y_pred_detection)\nrecall_det = recall_score(y_test_detection, y_pred_detection)\nf1_det = f1_score(y_test_detection, y_pred_detection)\n\n# Calculate accuracy for identification\naccuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\nprecision_iden = precision_score(y_test_identification, y_pred_identification, average=average_approach)\nrecall_iden = recall_score(y_test_identification, y_pred_identification, average=average_approach)\nf1_iden = f1_score(y_test_identification, y_pred_identification, average=average_approach)\n\n# Calculate accuracy for isolation\naccuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\nprecision_iso = precision_score(y_test_isolation, y_pred_isolation, average=average_approach)\nrecall_iso = recall_score(y_test_isolation, y_pred_isolation, average=average_approach)\nf1_iso = f1_score(y_test_isolation, y_pred_isolation, average=average_approach)\n\n\n# # Print results\n# print('Detection:')\n# print(f'    Accuracy: {accuracy_det:.3f}')\n# print(f'    Precision: {precision_det:.3f}')\n# print(f'    Recall: {recall_det:.3f}')\n# print(f'    F1-score: {f1_det:.3f}')\n\n# print('Identification:')\n# print(f'    Accuracy: {accuracy_iden:.3f}')\n# print(f'    Precision: {precision_iden:.3f}')\n# print(f'    Recall: {recall_iden:.3f}')\n# print(f'    F1-score: {f1_iden:.3f}')\n\n# print('Isolation:')\n# print(f'    Accuracy: {accuracy_iso:.3f}')\n# print(f'    Precision: {precision_iso:.3f}')\n# print(f'    Recall: {recall_iso:.3f}')\n# print(f'    F1-score: {f1_iso:.3f}')\n\nprint('Classification Report:')\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v3.4.2 (save classifcation outputs as heatmap figures instead of print)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\n\nnum_scenarios = 50\n\n# hyper-parameter\nnum_quad = 5\n\ninput_lstm = 64\nshared_lstm = 256\nseq_len = 40\nseq_overlap = seq_len - 1\n\nepoch_val = 100\nbatch_size_val = 128\n\nquad_feature = 10   # 10 for all data, 6 for only sensors\naverage_approach = 'macro'\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-network-of-quadcopters-50k/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\n# Function to create identification vector\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    for col_idx in [51, 54, 57, 60, 62][:num_quad]:\n        if row.iloc[col_idx] > 0:\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n    return attack_types\n\n# Dynamically handle labels and targets based on num_quad\ncols_to_check = [50, 53, 56, 59, 62][:num_quad]  # Select relevant columns\nlabels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\nlabels['type'] = data.apply(create_identification_vector, axis=1)\nlabels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n\n# remove other quads data and old labels\ndata = data.iloc[:, :num_quad * 10]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(num_quad):\n    X_train_heads.append(X_train[:, :, i*10:i*10+quad_feature])\n    X_test_heads.append(X_test[:, :, i*10:i*10+quad_feature])\n\n# 3. Model creation\n# 3.1 Model architecture\ninputs = []\nlstm_layers = []\n\n# Create input and LSTM layers based on num_quad\nfor i in range(num_quad):\n    input_layer = Input(shape=(seq_len, quad_feature))\n    lstm_layer = LSTM(input_lstm, return_sequences=True)(input_layer)\n    inputs.append(input_layer)\n    lstm_layers.append(lstm_layer)\n\n# Shared LSTM layer\nconcat = Concatenate()(lstm_layers)\nshared_lstm = LSTM(shared_lstm)(concat)\n\n# Outputs\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n# Model\nmodel = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train_heads,\n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation =\\\nmodel.predict(X_test_heads)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = (y_pred_identification > 0.5).astype(int)\ny_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n\n\n# Function to convert classification report to DataFrame\ndef report_to_df(report):\n    df = pd.DataFrame(report).transpose()\n    df = df.drop(columns=['support'], errors='ignore')\n    return df\n\n# Plotting function\ndef plot_and_save_heatmap(df, title, filename, req_rows):\n    plt.figure(figsize=(10, 6))\n    sns.heatmap(df.iloc[req_rows, :], annot=True, cmap='YlGnBu', fmt='.2f')  \n    plt.title(title)\n    plt.savefig(filename, format='png')\n    plt.show()\n\n# Sample classification reports\n# Assuming y_test and y_pred are already defined\nreport_detection = classification_report(y_test_detection, y_pred_detection, output_dict=True)\nreport_identification = classification_report(y_test_identification, y_pred_identification, output_dict=True)\nreport_isolation = classification_report(y_test_isolation, y_pred_isolation, output_dict=True)\n\n# Convert reports to DataFrames\ndf_detection = report_to_df(report_detection)\ndf_identification = report_to_df(report_identification)\ndf_isolation = report_to_df(report_isolation)\n\n# Create heatmaps for each report\nplot_and_save_heatmap(df_detection, \"Detection Report (Binary Classification)\", \"detection_report.png\", [0, 1, 3])\nplot_and_save_heatmap(df_identification, \"Identification Report (Multi-Binary Classification)\", \"identification_report.png\", [0, 1, 2, 4])\nplot_and_save_heatmap(df_isolation, \"Isolation Report (Multi-Binary Classification)\", \"isolation_report.png\", [0, 1, 2, 3, 4, 6])","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"special case for decentralzied of last 2 quads","metadata":{}},{"cell_type":"code","source":"# moz\n\nimport pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\n\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\nnum_scenarios = 30\n\n# hyper-parameter\n\ninput_lstm = 32\nshared_lstm = 128\nseq_len = 40\nseq_overlap = seq_len - 1\n\nepoch_val = 50\nbatch_size_val = 128\n\nquad_feature = 10   # 10 for all data, 6 for only sensors\naverage_approach = 'macro'\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-network-of-quadcopters-50k/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\n# Function to create identification vector\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    for col_idx in [51, 54, 57, 60, 62][3:]:\n        if row.iloc[col_idx] > 0:\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n    return attack_types\n\n# Dynamically handle labels and targets based on num_quad\ncols_to_check = [50, 53, 56, 59, 62][3:]  # Select relevant columns\nlabels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\nlabels['type'] = data.apply(create_identification_vector, axis=1)\nlabels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n\n# remove other quads data and old labels\ndata = data.iloc[:, 30:50]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# print(data_normalized.head())\n# print(data_normalized.shape)\n# moz\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(2):\n    X_train_heads.append(X_train[:, :, i*10:i*10+quad_feature])\n    X_test_heads.append(X_test[:, :, i*10:i*10+quad_feature])\n\n# 3. Model creation\n# 3.1 Model architecture\ninputs = []\nlstm_layers = []\n\n# Create input and LSTM layers based on num_quad\nfor i in range(2):\n    input_layer = Input(shape=(seq_len, quad_feature))\n    lstm_layer = LSTM(input_lstm, return_sequences=True)(input_layer)\n    inputs.append(input_layer)\n    lstm_layers.append(lstm_layer)\n\n# Shared LSTM layer\nconcat = Concatenate()(lstm_layers)\nshared_lstm = LSTM(shared_lstm)(concat)\n\n# Outputs\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\noutput_isolation = Dense(2, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n# Model\nmodel = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train_heads,\n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation =\\\nmodel.predict(X_test_heads)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = (y_pred_identification > 0.5).astype(int)\ny_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n\n\n# 3.5 print results for each column\ntraining_time = end_time - start_time\nprint(f\"Training Time: {training_time:.1f}\")\n\n\n# Calculate metrics for detection\naccuracy_det = accuracy_score(y_test_detection, y_pred_detection)\nprecision_det = precision_score(y_test_detection, y_pred_detection)\nrecall_det = recall_score(y_test_detection, y_pred_detection)\nf1_det = f1_score(y_test_detection, y_pred_detection)\n\n# Calculate accuracy for identification\naccuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\nprecision_iden = precision_score(y_test_identification, y_pred_identification, average=average_approach)\nrecall_iden = recall_score(y_test_identification, y_pred_identification, average=average_approach)\nf1_iden = f1_score(y_test_identification, y_pred_identification, average=average_approach)\n\n# Calculate accuracy for isolation\naccuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\nprecision_iso = precision_score(y_test_isolation, y_pred_isolation, average=average_approach)\nrecall_iso = recall_score(y_test_isolation, y_pred_isolation, average=average_approach)\nf1_iso = f1_score(y_test_isolation, y_pred_isolation, average=average_approach)\n\n\n# Print results\nprint('Detection:')\nprint(f'    Accuracy: {accuracy_det:.3f}')\nprint(f'    Precision: {precision_det:.3f}')\nprint(f'    Recall: {recall_det:.3f}')\nprint(f'    F1-score: {f1_det:.3f}')\n\nprint('Identification:')\nprint(f'    Accuracy: {accuracy_iden:.3f}')\nprint(f'    Precision: {precision_iden:.3f}')\nprint(f'    Recall: {recall_iden:.3f}')\nprint(f'    F1-score: {f1_iden:.3f}')\n\nprint('Isolation:')\nprint(f'    Accuracy: {accuracy_iso:.3f}')\nprint(f'    Precision: {precision_iso:.3f}')\nprint(f'    Recall: {recall_iso:.3f}')\nprint(f'    F1-score: {f1_iso:.3f}')\n\n# print('Classification Report:')\n# print(classification_report(y_test_detection, y_pred_detection))\n# print(classification_report(y_test_identification, y_pred_identification))\n# print(classification_report(y_test_isolation, y_pred_isolation))","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v3.2 code optimization","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\n\nnum_quad = 4\nnum_scenarios = 20\n\n# hyper-parameter\nseq_len = 40\nseq_overlap = seq_len - 1\nepoch_val = 50\nbatch_size_val = 128\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-network-of-quadcopters/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\n# Function to create identification vector\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    for col_idx in [51, 54, 57, 60, 62][:num_quad]:\n        if row.iloc[col_idx] > 0:\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n    return attack_types\n\n# Dynamically handle labels and targets based on num_quad\ncols_to_check = [50, 53, 56, 59, 62][:num_quad]  # Select relevant columns\nlabels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\nlabels['type'] = data.apply(create_identification_vector, axis=1)\nlabels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n    \n# remove other quads data and old labels\ndata = data.iloc[:, :num_quad * 10]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(num_quad):\n    X_train_heads.append(X_train[:, :, i*10:(i+1)*10])\n    X_test_heads.append(X_test[:, :, i*10:(i+1)*10])\n    \n# 3. Model creation\n# 3.1 Model architecture\ninputs = []\nlstm_layers = []\n\n# Create input and LSTM layers based on num_quad\nfor i in range(num_quad):\n    input_layer = Input(shape=(seq_len, 10))\n    lstm_layer = LSTM(32, return_sequences=True)(input_layer)\n    inputs.append(input_layer)\n    lstm_layers.append(lstm_layer)\n\n# Shared LSTM layer\nconcat = Concatenate()(lstm_layers)\nshared_lstm = LSTM(64)(concat)\n\n# Outputs\noutput_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\noutput_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\noutput_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n# Model\nmodel = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\nmodel.fit(X_train_heads, \n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\nend_time = time.time()\n\n\n# 3.4 model test\ny_pred_detection, y_pred_identification, y_pred_isolation =\\\nmodel.predict(X_test_heads)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = (y_pred_identification > 0.5).astype(int)\ny_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n\n\n# 3.5 print results for each column\ntraining_time = end_time - start_time\nprint(f\"Training Time: {training_time:.1f}\")\n\n\n# Calculate metrics for detection\naccuracy = accuracy_score(y_test_detection, y_pred_detection)\nprecision = precision_score(y_test_detection, y_pred_detection)\nrecall = recall_score(y_test_detection, y_pred_detection)\nf1 = f1_score(y_test_detection, y_pred_detection)\n\n# Calculate accuracy for identification and isolation\naccuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\naccuracy_isol = accuracy_score(y_test_isolation, y_pred_isolation)\n\n# Print results\nprint(' Detection:')\nprint(f'    Accuracy: {accuracy:.3f}')\nprint(f'    Precision: {precision:.3f}')\nprint(f'    Recall: {recall:.3f}')\nprint(f'    F1-score: {f1:.3f}')\n\nprint(' Identification:')\nprint(f'    Accuracy: {accuracy_iden:.3f}')\n\nprint(' Localization:')\nprint(f'    Accuracy: {accuracy_isol:.3f}')\n\nprint(' Classification Report:')\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v3 (reduce output size!)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3\nnum_quad_features = 10\n\nnum_quad = 5\nnum_scenarios = 10\n\n# hyper-parameter\nseq_len = 40\nseq_overlap = seq_len - 1\nepoch_val = 5\nbatch_size_val = 128\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-network-of-quadcopters/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# combine network labels together\nlabels = pd.DataFrame()\n\ndef create_identification_vector(row):\n    attack_types = [0, 0, 0]  # Initial vector (no attack)\n    ctr = 0\n    for col_idx in [51, 54, 57, 60, 62]:\n        if row.iloc[col_idx] > 0:  # Use .iloc for positional indexing\n            attack_type_idx = int(row.iloc[col_idx]) - 1\n            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n        ctr += 1\n        if ctr == num_quad:\n            break\n    return attack_types\n\n# Create new labels\nif num_quad == 2:\n    labels['label'] = ((data.iloc[:, 50] == 1) | (data.iloc[:, 53] == 1)).astype(int)\n    labels['type'] = data.apply(create_identification_vector, axis=1)\n    labels['target'] = data.apply(lambda row: [int(row.iloc[50]), int(row.iloc[53])], axis=1)\n\nif num_quad == 3:\n    labels['label'] = ((data.iloc[:, 50] == 1) | (data.iloc[:, 53] == 1) | (data.iloc[:, 56] == 1)).astype(int)\n    labels['type'] = data.apply(create_identification_vector, axis=1)\n    labels['target'] = data.apply(lambda row: [int(row.iloc[50]), int(row.iloc[53]), int(row.iloc[56])], axis=1)\n\nif num_quad == 4:\n    labels['label'] = ((data.iloc[:, 50] == 1) | (data.iloc[:, 53] == 1) | (data.iloc[:, 56] == 1) | (data.iloc[:, 59] == 1)).astype(int)\n    labels['type'] = data.apply(create_identification_vector, axis=1)\n    labels['target'] = data.apply(lambda row: [int(row.iloc[50]), int(row.iloc[53]), int(row.iloc[56]), int(row.iloc[59])], axis=1)\n    \nif num_quad == 5:\n    labels['label'] = ((data.iloc[:, 50] == 1) | (data.iloc[:, 53] == 1) | (data.iloc[:, 56] == 1) | (data.iloc[:, 59] == 1) | (data.iloc[:, 62] == 1)).astype(int)\n    labels['type'] = data.apply(create_identification_vector, axis=1)\n    labels['target'] = data.apply(lambda row: [int(row.iloc[50]), int(row.iloc[53]), int(row.iloc[56]), int(row.iloc[59]), int(row.iloc[62])], axis=1)\n   \n    \n# remove other quads data and old labels\ndata = data.iloc[:, :num_quad * 10]\n\n# 1.1 normalization\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n\n# 2.2 reshape data for LSTM network\ny_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\ny_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\nX_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n\ny_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\ny_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\ny_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\nX_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nX_train_heads = []\nX_test_heads = []\n\nfor i in range(num_quad):\n    X_train_heads.append(X_train[:, :, i*10:(i+1)*10])\n    X_test_heads.append(X_test[:, :, i*10:(i+1)*10])\n    \n# 3. model creation\n# 3.1 model archiecture\nif num_quad == 2:\n  # input\n  input_1 = Input(shape=(seq_len, 10))\n  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n  input_2 = Input(shape=(seq_len, 10))\n  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n\n  # shared\n  concat = Concatenate()([lstm_1, lstm_2])\n  shared_lstm = LSTM(64)(concat)\n\n  # output\n  output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n  output_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\n  output_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n  \n  # model\n  model = Model(inputs=[input_1, input_2], outputs=[output_detection, output_identification, output_isolation])\n\n\n    \nif num_quad == 3:\n  # input\n  input_1 = Input(shape=(seq_len, 10))\n  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n  input_2 = Input(shape=(seq_len, 10))\n  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n  input_3 = Input(shape=(seq_len, 10))\n  lstm_3 = LSTM(32, return_sequences=True)(input_3)\n\n  # shared\n  concat = Concatenate()([lstm_1, lstm_2, lstm_3])\n  shared_lstm = LSTM(64)(concat)\n\n  # output\n  output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n  output_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\n  output_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n  \n  # model\n  model = Model(inputs=[input_1, input_2, input_3], outputs=[output_detection, output_identification, output_isolation])\n  \nif num_quad == 4:\n    # input\n    input_1 = Input(shape=(seq_len, 10))\n    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n    input_2 = Input(shape=(seq_len, 10))\n    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n    input_3 = Input(shape=(seq_len, 10))\n    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n    input_4 = Input(shape=(seq_len, 10))\n    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n\n    # shared\n    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4])\n    shared_lstm = LSTM(64)(concat)\n\n    # output\n    output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n    output_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\n    output_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n    # model\n    model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=[output_detection, output_identification, output_isolation])\n    \n\nif num_quad == 5:\n    # input\n    input_1 = Input(shape=(seq_len, 10))\n    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n    input_2 = Input(shape=(seq_len, 10))\n    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n    input_3 = Input(shape=(seq_len, 10))\n    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n    input_4 = Input(shape=(seq_len, 10))\n    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n    input_5 = Input(shape=(seq_len, 10))\n    lstm_5 = LSTM(32, return_sequences=True)(input_5)\n\n    # shared\n    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4, lstm_5])\n    shared_lstm = LSTM(64)(concat)\n\n    # output\n    output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n    output_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\n    output_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n\n    # model\n    model = Model(inputs=[input_1, input_2, input_3, input_4, input_5], outputs=[output_detection, output_identification, output_isolation])\n\n\n# 3.2 model compile\nmodel.compile(\n  loss={\n      'detection_output': 'binary_crossentropy',\n      'identification_output': 'binary_crossentropy',\n      'isolation_output': 'binary_crossentropy'\n  },\n  optimizer='adam',\n  metrics={\n      'detection_output': ['accuracy'],\n      'identification_output': ['accuracy'],\n      'isolation_output': ['accuracy']\n  }\n)\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\n    \n\nmodel.fit(X_train_heads, \n         [y_train_detection, y_train_identification, y_train_isolation],\n         epochs=epoch_val, batch_size=batch_size_val)\n\nend_time = time.time()\n\n\n# 3.4 model test\n  \ny_pred_detection, y_pred_identification, y_pred_isolation =\\\nmodel.predict(X_test_heads)\n\n# Convert predictions for binary and multi-class\ny_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\ny_pred_identification = (y_pred_identification > 0.5).astype(int)\ny_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n\n\n# 3.5 print results for each column\ntraining_time = end_time - start_time\nprint(f\"Training Time: {training_time:.1f}\")\n\n\n# Calculate metrics for detection\naccuracy = accuracy_score(y_test_detection, y_pred_detection)\nprecision = precision_score(y_test_detection, y_pred_detection)\nrecall = recall_score(y_test_detection, y_pred_detection)\nf1 = f1_score(y_test_detection, y_pred_detection)\n\n# Calculate accuracy for identification and isolation\naccuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\naccuracy_isol = accuracy_score(y_test_isolation, y_pred_isolation)\n\n# Print results\nprint(' Detection:')\nprint(f'    Accuracy: {accuracy:.3f}')\nprint(f'    Precision: {precision:.3f}')\nprint(f'    Recall: {recall:.3f}')\nprint(f'    F1-score: {f1:.3f}')\n\nprint(' Identification:')\nprint(f'    Accuracy: {accuracy_iden:.3f}')\n\nprint(' Localization:')\nprint(f'    Accuracy: {accuracy_isol:.3f}')\n\nprint(' Classification Report:')\nprint(classification_report(y_test_detection, y_pred_detection))\nprint(classification_report(y_test_identification, y_pred_identification))\nprint(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"v2 (update for 2-5 quads)","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom numpy import array\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import StandardScaler\nimport time\n\n# parameters\nscenario_length = 1000\nnum_attack_types = 3 + 1\nnum_attack_targets = 10 + 1\nnum_quad_features = 10\n\nnum_quad = 2\nnum_scenarios = 30\n\n# hyper-parameter\nseq_len = 40\nseq_overlap = seq_len - 1\nepoch_val = 50\nbatch_size_val = 128\n\n# 1 data preprocessing\ndata = pd.read_csv('/kaggle/input/cyber-attack-detection-for-network-of-quadcopters/dataset.csv')\n\n# drop time\ndata = data.drop(columns=['time'])\n\n# remove other quads data\nif num_quad == 2:\n  data = data.iloc[:, list(range(20)) + list(range(50, 56))]\nif num_quad == 3:\n  data = data.iloc[:, list(range(30)) + list(range(50, 59))]\nif num_quad == 4:\n  data = data.iloc[:, list(range(40)) + list(range(50, 62))]\nif num_quad == 5:\n  data = data.iloc[:, list(range(50)) + list(range(50, 65))]\n\n# 1.1 normalization\nif num_quad == 2:\n  labels = data[data.columns[20:26]] \n  data.drop(columns=data.columns[20:26], inplace=True)\nif num_quad == 3:\n  labels = data[data.columns[30:39]] \n  data.drop(columns=data.columns[30:39], inplace=True)  \nif num_quad == 4:\n  labels = data[data.columns[40:52]] \n  data.drop(columns=data.columns[40:52], inplace=True)\nif num_quad == 5:\n  labels = data[data.columns[50:65]] \n  data.drop(columns=data.columns[50:65], inplace=True)\n\nscaler = StandardScaler()\ndata_normalized = scaler.fit_transform(data)\ndata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\ndata_normalized = pd.concat([data_normalized, labels], axis=1)\n\n# 1.2 sequence generation\nsequences = []\nstep_len = seq_len - seq_overlap\n\nfor s in range(0, num_scenarios):\n    scenario_start = s * scenario_length\n    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n        sequence = data_normalized[i:i + seq_len]\n        sequences.append(sequence)\ndata_sequences = array(sequences)\n\n# 2 data preperation\n# 2.1 train-test split\ndata_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\nX_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\nX_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\nX_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n\n# 2.2 reshape data for LSTM network\nif num_quad == 2:\n  print(type(X_train), X_train.dtype)\n  moz\n  y_train_detection_1 = X_train[:, -1, -6]\n  y_train_identification_1 = X_train[:, -1, -5]\n  y_train_isolation_1 = X_train[:, -1, -4]\n  y_train_detection_2 = X_train[:, -1, -3]\n  y_train_identification_2 = X_train[:, -1, -2]\n  y_train_isolation_2 = X_train[:, -1, -1]\n  X_train = X_train[:, :, :-6]\n\n  y_test_detection_1 = X_test[:, -1, -6]\n  y_test_identification_1 = X_test[:, -1, -5]\n  y_test_isolation_1 = X_test[:, -1, -4]\n  y_test_detection_2 = X_test[:, -1, -3]\n  y_test_identification_2 = X_test[:, -1, -2]\n  y_test_isolation_2 = X_test[:, -1, -1]\n  X_test = X_test[:, :, :-6]\n\nif num_quad == 3:\n  y_train_detection_1 = X_train[:, -1, -9]\n  y_train_identification_1 = X_train[:, -1, -8]\n  y_train_isolation_1 = X_train[:, -1, -7]\n  y_train_detection_2 = X_train[:, -1, -6]\n  y_train_identification_2 = X_train[:, -1, -5]\n  y_train_isolation_2 = X_train[:, -1, -4]\n  y_train_detection_3 = X_train[:, -1, -3]\n  y_train_identification_3 = X_train[:, -1, -2]\n  y_train_isolation_3 = X_train[:, -1, -1]\n  X_train = X_train[:, :, :-9]\n\n  y_test_detection_1 = X_test[:, -1, -9]\n  y_test_identification_1 = X_test[:, -1, -8]\n  y_test_isolation_1 = X_test[:, -1, -7]\n  y_test_detection_2 = X_test[:, -1, -6]\n  y_test_identification_2 = X_test[:, -1, -5]\n  y_test_isolation_2 = X_test[:, -1, -4]\n  y_test_detection_3 = X_test[:, -1, -3]\n  y_test_identification_3 = X_test[:, -1, -2]\n  y_test_isolation_3 = X_test[:, -1, -1]\n  X_test = X_test[:, :, :-9]\n\nif num_quad == 4:\n  y_train_detection_1 = X_train[:, -1, -12]\n  y_train_identification_1 = X_train[:, -1, -11]\n  y_train_isolation_1 = X_train[:, -1, -10]\n  y_train_detection_2 = X_train[:, -1, -9]\n  y_train_identification_2 = X_train[:, -1, -8]\n  y_train_isolation_2 = X_train[:, -1, -7]\n  y_train_detection_3 = X_train[:, -1, -6]\n  y_train_identification_3 = X_train[:, -1, -5]\n  y_train_isolation_3 = X_train[:, -1, -4]\n  y_train_detection_4 = X_train[:, -1, -3]\n  y_train_identification_4 = X_train[:, -1, -2]\n  y_train_isolation_4 = X_train[:, -1, -1]\n  X_train = X_train[:, :, :-12]\n\n  y_test_detection_1 = X_test[:, -1, -12]\n  y_test_identification_1 = X_test[:, -1, -11]\n  y_test_isolation_1 = X_test[:, -1, -10]\n  y_test_detection_2 = X_test[:, -1, -9]\n  y_test_identification_2 = X_test[:, -1, -8]\n  y_test_isolation_2 = X_test[:, -1, -7]\n  y_test_detection_3 = X_test[:, -1, -6]\n  y_test_identification_3 = X_test[:, -1, -5]\n  y_test_isolation_3 = X_test[:, -1, -4]\n  y_test_detection_4 = X_test[:, -1, -3]\n  y_test_identification_4 = X_test[:, -1, -2]\n  y_test_isolation_4 = X_test[:, -1, -1]\n  X_test = X_test[:, :, :-12]\n\nif num_quad == 5:\n  y_train_detection_1 = X_train[:, -1, -15]\n  y_train_identification_1 = X_train[:, -1, -14]\n  y_train_isolation_1 = X_train[:, -1, -13]\n  y_train_detection_2 = X_train[:, -1, -12]\n  y_train_identification_2 = X_train[:, -1, -11]\n  y_train_isolation_2 = X_train[:, -1, -10]\n  y_train_detection_3 = X_train[:, -1, -9]\n  y_train_identification_3 = X_train[:, -1, -8]\n  y_train_isolation_3 = X_train[:, -1, -7]\n  y_train_detection_4 = X_train[:, -1, -6]\n  y_train_identification_4 = X_train[:, -1, -5]\n  y_train_isolation_4 = X_train[:, -1, -4]\n  y_train_detection_5 = X_train[:, -1, -3]\n  y_train_identification_5 = X_train[:, -1, -2]\n  y_train_isolation_5 = X_train[:, -1, -1]\n  X_train = X_train[:, :, :-15]\n\n  y_test_detection_1 = X_test[:, -1, -15]\n  y_test_identification_1 = X_test[:, -1, -14]\n  y_test_isolation_1 = X_test[:, -1, -13]\n  y_test_detection_2 = X_test[:, -1, -12]\n  y_test_identification_2 = X_test[:, -1, -11]\n  y_test_isolation_2 = X_test[:, -1, -10]\n  y_test_detection_3 = X_test[:, -1, -9]\n  y_test_identification_3 = X_test[:, -1, -8]\n  y_test_isolation_3 = X_test[:, -1, -7]\n  y_test_detection_4 = X_test[:, -1, -6]\n  y_test_identification_4 = X_test[:, -1, -5]\n  y_test_isolation_4 = X_test[:, -1, -4]\n  y_test_detection_5 = X_test[:, -1, -3]\n  y_test_identification_5 = X_test[:, -1, -2]\n  y_test_isolation_5 = X_test[:, -1, -1]\n  X_test = X_test[:, :, :-15]\n\n\n# Split X_train into seperate part for different input heads for each quadcopter\nif num_quad == 2:\n  X_train_head_1 = X_train[:, :, 0:10]\n  X_train_head_2 = X_train[:, :, 10:20]\n\n  X_test_head_1 = X_test[:, :, 0:10]\n  X_test_head_2 = X_test[:, :, 10:20] \n\nif num_quad == 3:\n  X_train_head_1 = X_train[:, :, 0:10]\n  X_train_head_2 = X_train[:, :, 10:20]\n  X_train_head_3 = X_train[:, :, 20:30]\n\n  X_test_head_1 = X_test[:, :, 0:10]\n  X_test_head_2 = X_test[:, :, 10:20]\n  X_test_head_3 = X_test[:, :, 20:30]\n\nif num_quad == 4:\n  X_train_head_1 = X_train[:, :, 0:10]\n  X_train_head_2 = X_train[:, :, 10:20]\n  X_train_head_3 = X_train[:, :, 20:30]\n  X_train_head_4 = X_train[:, :, 30:40]\n\n  X_test_head_1 = X_test[:, :, 0:10]\n  X_test_head_2 = X_test[:, :, 10:20]\n  X_test_head_3 = X_test[:, :, 20:30]\n  X_test_head_4 = X_test[:, :, 30:40]\n\nif num_quad == 5:\n  X_train_head_1 = X_train[:, :, 0:10]\n  X_train_head_2 = X_train[:, :, 10:20]\n  X_train_head_3 = X_train[:, :, 20:30]\n  X_train_head_4 = X_train[:, :, 30:40]\n  X_train_head_5 = X_train[:, :, 40:50]\n\n  X_test_head_1 = X_test[:, :, 0:10]\n  X_test_head_2 = X_test[:, :, 10:20]\n  X_test_head_3 = X_test[:, :, 20:30]\n  X_test_head_4 = X_test[:, :, 30:40]\n  X_test_head_5 = X_test[:, :, 40:50]\n\n\n# 3. model creation\n# 3.1 model archiecture\nif num_quad == 2:\n  # input\n  input_1 = Input(shape=(seq_len, 10))\n  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n  input_2 = Input(shape=(seq_len, 10))\n  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n\n  # shared\n  concat = Concatenate()([lstm_1, lstm_2])\n  shared_lstm = LSTM(64)(concat)\n\n  # output\n  output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n  output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n  output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n  output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n  output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n  output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n  \n  model = Model(inputs=[input_1, input_2], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n                                                    output_detection_2, output_identification_2, output_isolation_2])\n\nif num_quad == 3:\n  # input\n  input_1 = Input(shape=(seq_len, 10))\n  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n  input_2 = Input(shape=(seq_len, 10))\n  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n  input_3 = Input(shape=(seq_len, 10))\n  lstm_3 = LSTM(32, return_sequences=True)(input_3)\n\n  # shared\n  concat = Concatenate()([lstm_1, lstm_2, lstm_3])\n  shared_lstm = LSTM(64)(concat)\n\n  # output\n  output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n  output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n  output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n  output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n  output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n  output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n  output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n  output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n  output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n\n  model = Model(inputs=[input_1, input_2, input_3], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n                                                             output_detection_2, output_identification_2, output_isolation_2, \n                                                             output_detection_3, output_identification_3, output_isolation_3])\n  \nif num_quad == 4:\n    # input\n    input_1 = Input(shape=(seq_len, 10))\n    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n    input_2 = Input(shape=(seq_len, 10))\n    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n    input_3 = Input(shape=(seq_len, 10))\n    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n    input_4 = Input(shape=(seq_len, 10))\n    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n\n    # shared\n    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4])\n    shared_lstm = LSTM(64)(concat)\n\n    # output\n    output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n    output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n    output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n    output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n    output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n    output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n    output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n    output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n    output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n    output_detection_4 = Dense(1, activation='sigmoid', name='detection_output_4')(shared_lstm)\n    output_identification_4 = Dense(num_attack_types, activation='softmax', name='identification_output_4')(shared_lstm)\n    output_isolation_4 = Dense(num_attack_targets, activation='softmax', name='isolation_output_4')(shared_lstm)\n\n    model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n                                                                      output_detection_2, output_identification_2, output_isolation_2,\n                                                                      output_detection_3, output_identification_3, output_isolation_3,\n                                                                      output_detection_4, output_identification_4, output_isolation_4])\n\nif num_quad == 5:\n    # input\n    input_1 = Input(shape=(seq_len, 10))\n    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n    input_2 = Input(shape=(seq_len, 10))\n    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n    input_3 = Input(shape=(seq_len, 10))\n    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n    input_4 = Input(shape=(seq_len, 10))\n    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n    input_5 = Input(shape=(seq_len, 10))\n    lstm_5 = LSTM(32, return_sequences=True)(input_5)\n\n    # shared\n    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4, lstm_5])\n    shared_lstm = LSTM(64)(concat)\n\n    # output\n    output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n    output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n    output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n    output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n    output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n    output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n    output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n    output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n    output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n    output_detection_4 = Dense(1, activation='sigmoid', name='detection_output_4')(shared_lstm)\n    output_identification_4 = Dense(num_attack_types, activation='softmax', name='identification_output_4')(shared_lstm)\n    output_isolation_4 = Dense(num_attack_targets, activation='softmax', name='isolation_output_4')(shared_lstm)\n    output_detection_5 = Dense(1, activation='sigmoid', name='detection_output_5')(shared_lstm)\n    output_identification_5 = Dense(num_attack_types, activation='softmax', name='identification_output_5')(shared_lstm)\n    output_isolation_5 = Dense(num_attack_targets, activation='softmax', name='isolation_output_5')(shared_lstm)\n\n    model = Model(inputs=[input_1, input_2, input_3, input_4, input_5], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n                                                                      output_detection_2, output_identification_2, output_isolation_2,\n                                                                      output_detection_3, output_identification_3, output_isolation_3,\n                                                                      output_detection_4, output_identification_4, output_isolation_4,\n                                                                      output_detection_5, output_identification_5, output_isolation_5])\n\n\n# 3.2 model compile\nif num_quad == 2:\n  model.compile(\n      loss={\n          'detection_output_1': 'binary_crossentropy',\n          'identification_output_1': 'sparse_categorical_crossentropy',\n          'isolation_output_1': 'sparse_categorical_crossentropy',\n          'detection_output_2': 'binary_crossentropy',\n          'identification_output_2': 'sparse_categorical_crossentropy',\n          'isolation_output_2': 'sparse_categorical_crossentropy'\n      },\n      optimizer='adam',\n      metrics={\n          'detection_output_1': ['accuracy'],\n          'identification_output_1': ['accuracy'],\n          'isolation_output_1': ['accuracy'],\n          'detection_output_2': ['accuracy'],\n          'identification_output_2': ['accuracy'],\n          'isolation_output_2': ['accuracy']\n      }\n  )\n\nif num_quad == 3:\n  model.compile(\n      loss={\n          'detection_output_1': 'binary_crossentropy',\n          'identification_output_1': 'sparse_categorical_crossentropy',\n          'isolation_output_1': 'sparse_categorical_crossentropy',\n          'detection_output_2': 'binary_crossentropy',\n          'identification_output_2': 'sparse_categorical_crossentropy',\n          'isolation_output_2': 'sparse_categorical_crossentropy',\n          'detection_output_3': 'binary_crossentropy',\n          'identification_output_3': 'sparse_categorical_crossentropy',\n          'isolation_output_3': 'sparse_categorical_crossentropy'\n      },\n      optimizer='adam',\n      metrics={\n          'detection_output_1': ['accuracy'],\n          'identification_output_1': ['accuracy'],\n          'isolation_output_1': ['accuracy'],\n          'detection_output_2': ['accuracy'],\n          'identification_output_2': ['accuracy'],\n          'isolation_output_2': ['accuracy'], \n          'detection_output_3': ['accuracy'],\n          'identification_output_3': ['accuracy'],\n          'isolation_output_3': ['accuracy']\n      }\n  )\n\nif num_quad == 4:\n  model.compile(\n      loss={\n          'detection_output_1': 'binary_crossentropy',\n          'identification_output_1': 'sparse_categorical_crossentropy',\n          'isolation_output_1': 'sparse_categorical_crossentropy',\n          'detection_output_2': 'binary_crossentropy',\n          'identification_output_2': 'sparse_categorical_crossentropy',\n          'isolation_output_2': 'sparse_categorical_crossentropy',\n          'detection_output_3': 'binary_crossentropy',\n          'identification_output_3': 'sparse_categorical_crossentropy',\n          'isolation_output_3': 'sparse_categorical_crossentropy',\n          'detection_output_4': 'binary_crossentropy',\n          'identification_output_4': 'sparse_categorical_crossentropy',\n          'isolation_output_4': 'sparse_categorical_crossentropy'\n      },\n      optimizer='adam',\n      metrics={\n          'detection_output_1': ['accuracy'],\n          'identification_output_1': ['accuracy'],\n          'isolation_output_1': ['accuracy'],\n          'detection_output_2': ['accuracy'],\n          'identification_output_2': ['accuracy'],\n          'isolation_output_2': ['accuracy'], \n          'detection_output_3': ['accuracy'],\n          'identification_output_3': ['accuracy'],\n          'isolation_output_3': ['accuracy'],\n          'detection_output_4': ['accuracy'],\n          'identification_output_4': ['accuracy'],\n          'isolation_output_4': ['accuracy']\n      }\n  )\n\nif num_quad == 5:\n  model.compile(\n      loss={\n          'detection_output_1': 'binary_crossentropy',\n          'identification_output_1': 'sparse_categorical_crossentropy',\n          'isolation_output_1': 'sparse_categorical_crossentropy',\n          'detection_output_2': 'binary_crossentropy',\n          'identification_output_2': 'sparse_categorical_crossentropy',\n          'isolation_output_2': 'sparse_categorical_crossentropy',\n          'detection_output_3': 'binary_crossentropy',\n          'identification_output_3': 'sparse_categorical_crossentropy',\n          'isolation_output_3': 'sparse_categorical_crossentropy',\n          'detection_output_4': 'binary_crossentropy',\n          'identification_output_4': 'sparse_categorical_crossentropy',\n          'isolation_output_4': 'sparse_categorical_crossentropy',\n          'detection_output_5': 'binary_crossentropy',\n          'identification_output_5': 'sparse_categorical_crossentropy',\n          'isolation_output_5': 'sparse_categorical_crossentropy'\n      },\n      optimizer='adam',\n      metrics={\n          'detection_output_1': ['accuracy'],\n          'identification_output_1': ['accuracy'],\n          'isolation_output_1': ['accuracy'],\n          'detection_output_2': ['accuracy'],\n          'identification_output_2': ['accuracy'],\n          'isolation_output_2': ['accuracy'], \n          'detection_output_3': ['accuracy'],\n          'identification_output_3': ['accuracy'],\n          'isolation_output_3': ['accuracy'],\n          'detection_output_4': ['accuracy'],\n          'identification_output_4': ['accuracy'],\n          'isolation_output_4': ['accuracy'], \n          'detection_output_5': ['accuracy'],\n          'identification_output_5': ['accuracy'],\n          'isolation_output_5': ['accuracy']\n      }\n  )\n\n\nprint(model.summary())\n\n\n# 3.3 model train\nstart_time = time.time()\n\nif num_quad == 2:\n#   print(X_train_head_1.shape)\n#   print(X_train_head_1[:2])\n#   print(X_train_head_2.shape)\n#   print(X_train_head_2[:2])\n#   print(y_train_detection_1.shape)\n#   print(y_train_detection[:2])\n#   print(y_train_identification_1.shape)\n#   print(y_train_identification[:2])\n#   print(y_train_isolation_1.shape)\n#   print(y_train_isolation[:2])  \n\n#   print(type(X_train_head_1), X_train_head_1.dtype)\n#   print(type(X_train_head_2), X_train_head_2.dtype)\n#   print(type(y_train_detection_1), y_train_detection_1.dtype)\n#   print(type(y_train_identification_1), y_train_identification_1.dtype)\n#   print(type(y_train_isolation_1), y_train_isolation_1.dtype)\n\n\n  model.fit([X_train_head_1, X_train_head_2], \n            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n             y_train_detection_2, y_train_identification_2, y_train_isolation_2],\n            epochs=epoch_val, batch_size=batch_size_val)\n  \nif num_quad == 3:\n  model.fit([X_train_head_1, X_train_head_2, X_train_head_3], \n            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n             y_train_detection_2, y_train_identification_2, y_train_isolation_2, \n             y_train_detection_3, y_train_identification_3, y_train_isolation_3],\n            epochs=epoch_val, batch_size=batch_size_val)\n\nif num_quad == 4:\n  model.fit([X_train_head_1, X_train_head_2, X_train_head_3, X_train_head_4], \n            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n              y_train_detection_2, y_train_identification_2, y_train_isolation_2,\n              y_train_detection_3, y_train_identification_3, y_train_isolation_3,\n              y_train_detection_4, y_train_identification_4, y_train_isolation_4],\n            epochs=epoch_val, batch_size=batch_size_val)\n\nif num_quad == 5:\n  model.fit([X_train_head_1, X_train_head_2, X_train_head_3, X_train_head_4, X_train_head_5], \n            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n              y_train_detection_2, y_train_identification_2, y_train_isolation_2,\n              y_train_detection_3, y_train_identification_3, y_train_isolation_3,\n              y_train_detection_4, y_train_identification_4, y_train_isolation_4,\n              y_train_detection_5, y_train_identification_5, y_train_isolation_5],\n            epochs=epoch_val, batch_size=batch_size_val)\n\n\nend_time = time.time()\n\n\n# 3.4 model test\nif num_quad == 2:\n  y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n  y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2 =\\\n  model.predict([X_test_head_1, X_test_head_2])\n\nif num_quad == 3:\n  y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n  y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n  y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3 =\\\n  model.predict([X_test_head_1, X_test_head_2, X_test_head_3])\n\nif num_quad == 4:\n    y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n    y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n    y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3, \\\n    y_pred_detection_4, y_pred_identification_4, y_pred_isolation_4 = \\\n    model.predict([X_test_head_1, X_test_head_2, X_test_head_3, X_test_head_4])\n\nif num_quad == 5:\n    y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n    y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n    y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3, \\\n    y_pred_detection_4, y_pred_identification_4, y_pred_isolation_4, \\\n    y_pred_detection_5, y_pred_identification_5, y_pred_isolation_5 = \\\n    model.predict([X_test_head_1, X_test_head_2, X_test_head_3, X_test_head_4, X_test_head_5])\n\n\n# Convert predictions for binary and multi-class\nif num_quad == 2:\n  y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n  y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n  y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n  y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n  y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n  y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n\nif num_quad == 3:\n  y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n  y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n  y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n  y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n  y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n  y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n  y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n  y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n  y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n\nif num_quad == 4:\n    y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n    y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n    y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n    y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n    y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n    y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n    y_pred_detection_4 = (y_pred_detection_4 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_4 = np.argmax(y_pred_identification_4, axis=1)\n    y_pred_isolation_4 = np.argmax(y_pred_isolation_4, axis=1)\n\nif num_quad == 5:\n    y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n    y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n    y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n    y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n    y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n    y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n    y_pred_detection_4 = (y_pred_detection_4 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_4 = np.argmax(y_pred_identification_4, axis=1)\n    y_pred_isolation_4 = np.argmax(y_pred_isolation_4, axis=1)\n    y_pred_detection_5 = (y_pred_detection_5 > 0.5).astype(int).reshape(-1)\n    y_pred_identification_5 = np.argmax(y_pred_identification_5, axis=1)\n    y_pred_isolation_5 = np.argmax(y_pred_isolation_5, axis=1)\n\n# 3.5 print results for each column\n\ntraining_time = end_time - start_time\nprint(f\"Training Time: {training_time:.1f}\")\n\n\nfor quad in range(1, num_quad+1):\n    # Retrieve the y_test and y_pred variables dynamically based on the quad number\n    y_test_detection = eval(f'y_test_detection_{quad}')\n    y_pred_detection = eval(f'y_pred_detection_{quad}')\n    y_test_identification = eval(f'y_test_identification_{quad}')\n    y_pred_identification = eval(f'y_pred_identification_{quad}')\n    y_test_isolation = eval(f'y_test_isolation_{quad}')\n    y_pred_isolation = eval(f'y_pred_isolation_{quad}')\n\n    # Calculate metrics for detection\n    accuracy = accuracy_score(y_test_detection, y_pred_detection)\n    precision = precision_score(y_test_detection, y_pred_detection)\n    recall = recall_score(y_test_detection, y_pred_detection)\n    f1 = f1_score(y_test_detection, y_pred_detection)\n    \n    # Calculate accuracy for identification and isolation\n    accuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\n    accuracy_isol = accuracy_score(y_test_isolation, y_pred_isolation)\n\n    # Print results\n    print(f'Quad {quad}:')\n    print(' Detection:')\n    print(f'    Accuracy: {accuracy:.3f}')\n    print(f'    Precision: {precision:.3f}')\n    print(f'    Recall: {recall:.3f}')\n    print(f'    F1-score: {f1:.3f}')\n    \n    print(' Identification:')\n    print(f'    Accuracy: {accuracy_iden:.3f}')\n    \n    print(' Localization:')\n    print(f'    Accuracy: {accuracy_isol:.3f}')\n    \n    print(' Classification Report:')\n    print(classification_report(y_test_detection, y_pred_detection))\n    print(classification_report(y_test_identification, y_pred_identification))\n    print(classification_report(y_test_isolation, y_pred_isolation))\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null}]}