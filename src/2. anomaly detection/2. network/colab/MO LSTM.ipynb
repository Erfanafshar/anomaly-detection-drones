{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPhOKn8MIBHdpKhsdQEvq+D"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["multi output LSTM (network)"],"metadata":{"id":"jRCvvGzaW5XM"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"OnPp6avvW1bF"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","\n","# parameters\n","num_features = 20\n","num_scenarios = 6\n","scenario_length = 1000\n","attack_type = 0 \t\t# 0: all, 1: DoS, 2: FDI, 3: Replay\n","num_attack_types = 3 + 1\n","num_attack_targets = 6 + 1\n","num_quad = 2\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 64\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1 data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2']]\n","data = data.drop(columns=['time', 'label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 6)\n","elif attack_type == 1:\n","    scenario_range = range(0, 2)\n","elif attack_type == 2:\n","    scenario_range = range(2, 4)\n","elif attack_type == 3:\n","    scenario_range = range(4, 6)\n","\n","for s in scenario_range:\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train_detection_1 = X_train[:, -1, -6]\n","y_train_identification_1 = X_train[:, -1, -5]\n","y_train_isolation_1 = X_train[:, -1, -4]\n","y_train_detection_2 = X_train[:, -1, -3]\n","y_train_identification_2 = X_train[:, -1, -2]\n","y_train_isolation_2 = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-6]\n","\n","y_test_detection_1 = X_test[:, -1, -6]\n","y_test_identification_1 = X_test[:, -1, -5]\n","y_test_isolation_1 = X_test[:, -1, -4]\n","y_test_detection_2 = X_test[:, -1, -3]\n","y_test_identification_2 = X_test[:, -1, -2]\n","y_test_isolation_2 = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-6]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","input_layer = Input(shape=(seq_len, num_features))\n","shared_lstm = LSTM(lstm_blocks)(input_layer)\n","output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","\n","model = Model(inputs=input_layer, outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                           output_detection_2, output_identification_2, output_isolation_2])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output_1': 'binary_crossentropy',\n","        'identification_output_1': 'sparse_categorical_crossentropy',\n","        'isolation_output_1': 'sparse_categorical_crossentropy',\n","        'detection_output_2': 'binary_crossentropy',\n","        'identification_output_2': 'sparse_categorical_crossentropy',\n","        'isolation_output_2': 'sparse_categorical_crossentropy'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output_1': ['accuracy'],\n","        'identification_output_1': ['accuracy'],\n","        'isolation_output_1': ['accuracy'],\n","        'detection_output_2': ['accuracy'],\n","        'identification_output_2': ['accuracy'],\n","        'isolation_output_2': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit(X_train, [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","                    y_train_detection_2, y_train_identification_2, y_train_isolation_2],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2 = model.predict(X_test)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","\n","# 3.5 print results for each column\n","\n","# quad 1\n","accuracy = accuracy_score(y_test_detection_1, y_pred_detection_1)\n","precision = precision_score(y_test_detection_1, y_pred_detection_1)\n","recall = recall_score(y_test_detection_1, y_pred_detection_1)\n","f1 = f1_score(y_test_detection_1, y_pred_detection_1)\n","\n","print('Quad 1:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification_1, y_pred_identification_1)\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_id:.3f}')\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation_1, y_pred_isolation_1)\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_iso:.3f}')\n","\n","\n","# quad 2\n","accuracy = accuracy_score(y_test_detection_2, y_pred_detection_2)\n","precision = precision_score(y_test_detection_2, y_pred_detection_2)\n","recall = recall_score(y_test_detection_2, y_pred_detection_2)\n","f1 = f1_score(y_test_detection_2, y_pred_detection_2)\n","\n","print('Quad 2:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification_2, y_pred_identification_2)\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_id:.3f}')\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation_2, y_pred_isolation_2)\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_iso:.3f}')\n","\n","\n"]}]}