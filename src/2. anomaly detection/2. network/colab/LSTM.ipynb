{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyN3GHPeAtcYAG1yKLl4gjiq"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["LSTM v2 (modify to work with new dataset, seperate attacks, simplify normalization)"],"metadata":{"id":"6ptgdEk6caY6"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense, Input\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","\n","# parameters\n","num_features = 20\n","num_scenarios = 6\n","scenario_length = 1000\n","attack_type = 0 \t\t# 0: all, 1: DoS, 2: FDI, 3: Replay\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 64\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1 data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.1 normalization\n","labels = data[['label_1', 'label_2']]\n","data = data.drop(columns=['time', 'label_1', 'label_2'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized[['label_1', 'label_2']] = labels\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 6)\n","elif attack_type == 1:\n","    scenario_range = range(0, 2)\n","elif attack_type == 2:\n","    scenario_range = range(2, 4)\n","elif attack_type == 3:\n","    scenario_range = range(4, 6)\n","\n","for s in scenario_range:\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train = X_train[:, -1, -2:]\n","y_test = X_test[:, -1, -2:]\n","X_train = X_train[:, :, :-2]\n","X_test = X_test[:, :, :-2]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","model = Sequential()\n","model.add(Input(shape=(seq_len, num_features)))\n","model.add(LSTM(lstm_blocks))\n","model.add(Dense(2, activation='sigmoid'))\n","\n","# 3.2 model compile\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","# 3.5 print results for each column\n","num_labels = y_test.shape[1]\n","\n","for i in range(num_labels):\n","    y_test_column = y_test[:, i]\n","    y_pred_column = y_pred[:, i]\n","\n","    accuracy = accuracy_score(y_test_column, y_pred_column)\n","    precision = precision_score(y_test_column, y_pred_column)\n","    recall = recall_score(y_test_column, y_pred_column)\n","    f1 = f1_score(y_test_column, y_pred_column)\n","\n","    print(f'Quad {i+1}:')\n","    print(f'  Accuracy: {accuracy:.3f}')\n","    print(f'  Precision: {precision:.3f}')\n","    print(f'  Recall: {recall:.3f}')\n","    print(f'  F1-score: {f1:.3f}')"],"metadata":{"id":"TtWS_1wtciat"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Network LSTM v1"],"metadata":{"id":"zRmNp_lRsNCc"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import LSTM, Dense\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","\n","# parameters\n","num_features = 20\n","num_scenarios = 6\n","scenario_length = 1000\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 64\n","epoch_val = 20\n","batch_size_val = 4\n","data_normalization = 1\n","\n","# 1. data preprocessing\n","data = pd.read_csv('dataset.csv')\n","\n","# 1.0.5 drop extra columns\n","data = data.drop(columns=['T_2', 'tau_phi_2', 'tau_theta_2', 'tau_psi_2'])\n","\n","# 1.1 normalization\n","if data_normalization == 0:\n","\tdata = data.drop(columns=['time'])\n","\tdata_normalized = data\n","else:\n","\tlabels = data[['label_1', 'label_2']]\n","\tdata = data.drop(columns=['time', 'label_1', 'label_2'])\n","\n","\tif data_normalization == 1:\n","\t\tscaler = StandardScaler()\n","\telif data_normalization == 2:\n","\t\tscaler = MinMaxScaler()\n","\n","\tdata_normalized = scaler.fit_transform(data)\n","\tdata_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","\tdata_normalized[['label_1', 'label_2']] = labels\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","for s in range(num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train = X_train[:, -1, -2:]\n","y_test = X_test[:, -1, -2:]\n","X_train = X_train[:, :, :-2]\n","X_test = X_test[:, :, :-2]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","model = Sequential()\n","model.add(LSTM(lstm_blocks, input_shape=(seq_len, num_features)))\n","model.add(Dense(2, activation='sigmoid'))\n","\n","# 3.2 model compile\n","model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit(X_train, y_train, epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_prob = model.predict(X_test)\n","y_pred = (y_pred_prob > 0.5).astype(int)\n","\n","# 3.5 print results for each column\n","num_labels = y_test.shape[1]\n","\n","for i in range(num_labels):\n","    y_test_column = y_test[:, i]\n","    y_pred_column = y_pred[:, i]\n","\n","    accuracy = accuracy_score(y_test_column, y_pred_column)\n","    precision = precision_score(y_test_column, y_pred_column)\n","    recall = recall_score(y_test_column, y_pred_column)\n","    f1 = f1_score(y_test_column, y_pred_column)\n","\n","    print(f'Quad {i+1}:')\n","    print(f'Accuracy: {accuracy:.3f}')\n","    print(f'Precision: {precision:.3f}')\n","    print(f'Recall: {recall:.3f}')\n","    print(f'F1-score: {f1:.3f}')\n","\n"],"metadata":{"id":"RUw_JxYvXQxR","collapsed":true},"execution_count":null,"outputs":[]}]}