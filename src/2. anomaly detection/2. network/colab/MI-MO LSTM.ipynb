{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPsdp57LCsNalZvS4RgBMA8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["v3.3 code optimization, output print fixed"],"metadata":{"id":"XRZg3PRjd5IG"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","import time\n","from google.colab import drive\n","\n","\n","# parameters\n","scenario_length = 1000\n","num_attack_types = 3\n","num_quad_features = 10\n","\n","num_quad = 4\n","num_scenarios = 30\n","\n","# hyper-parameter\n","input_lstm = 64\n","shared_lstm = 256\n","seq_len = 100\n","seq_overlap = seq_len - 1\n","\n","epoch_val = 50\n","batch_size_val = 128\n","\n","average_approach = 'macro'\n","\n","# 1 data preprocessing\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/My Drive/code/dataset/network/dataset.csv'\n","data = pd.read_csv(dataset_path)\n","\n","# drop time\n","data = data.drop(columns=['time'])\n","\n","# combine network labels together\n","labels = pd.DataFrame()\n","\n","# Function to create identification vector\n","def create_identification_vector(row):\n","    attack_types = [0, 0, 0]  # Initial vector (no attack)\n","    for col_idx in [51, 54, 57, 60, 62][:num_quad]:\n","        if row.iloc[col_idx] > 0:\n","            attack_type_idx = int(row.iloc[col_idx]) - 1\n","            attack_types[attack_type_idx] = 1  # Mark the correct attack type as 1\n","    return attack_types\n","\n","# Dynamically handle labels and targets based on num_quad\n","cols_to_check = [50, 53, 56, 59, 62][:num_quad]  # Select relevant columns\n","labels['label'] = data.iloc[:, cols_to_check].apply(lambda row: any(row == 1), axis=1).astype(int)\n","labels['type'] = data.apply(create_identification_vector, axis=1)\n","labels['target'] = data.iloc[:, cols_to_check].apply(lambda row: row.astype(int).tolist(), axis=1)\n","\n","# remove other quads data and old labels\n","data = data.iloc[:, :num_quad * 10]\n","\n","# 1.1 normalization\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","\n","# 2.2 reshape data for LSTM network\n","y_train_detection = np.array(X_train[:, -1, -3].reshape(-1, 1), dtype=np.float32)\n","y_train_identification = np.array(X_train[:, -1, -2].tolist(), dtype=np.float32)\n","y_train_isolation = np.array(X_train[:, -1, -1].tolist(), dtype=np.float32)\n","X_train = np.array(X_train[:, :, :-3], dtype=np.float32)\n","\n","y_test_detection = np.array(X_test[:, -1, -3].reshape(-1, 1), dtype=np.float32)\n","y_test_identification = np.array(X_test[:, -1, -2].tolist(), dtype=np.float32)\n","y_test_isolation = np.array(X_test[:, -1, -1].tolist(), dtype=np.float32)\n","X_test = np.array(X_test[:, :, :-3], dtype=np.float32)\n","\n","\n","# Split X_train into seperate part for different input heads for each quadcopter\n","X_train_heads = []\n","X_test_heads = []\n","\n","for i in range(num_quad):\n","    X_train_heads.append(X_train[:, :, i*10:(i+1)*10])\n","    X_test_heads.append(X_test[:, :, i*10:(i+1)*10])\n","\n","# 3. Model creation\n","# 3.1 Model architecture\n","inputs = []\n","lstm_layers = []\n","\n","# Create input and LSTM layers based on num_quad\n","for i in range(num_quad):\n","    input_layer = Input(shape=(seq_len, 10))\n","    lstm_layer = LSTM(input_lstm, return_sequences=True)(input_layer)\n","    inputs.append(input_layer)\n","    lstm_layers.append(lstm_layer)\n","\n","# Shared LSTM layer\n","concat = Concatenate()(lstm_layers)\n","shared_lstm = LSTM(shared_lstm)(concat)\n","\n","# Outputs\n","output_detection = Dense(1, activation='sigmoid', name='detection_output')(shared_lstm)\n","output_identification = Dense(num_attack_types, activation='sigmoid', name='identification_output')(shared_lstm)\n","output_isolation = Dense(num_quad, activation='sigmoid', name='isolation_output')(shared_lstm)\n","\n","# Model\n","model = Model(inputs=inputs, outputs=[output_detection, output_identification, output_isolation])\n","\n","\n","# 3.2 model compile\n","model.compile(\n","  loss={\n","      'detection_output': 'binary_crossentropy',\n","      'identification_output': 'binary_crossentropy',\n","      'isolation_output': 'binary_crossentropy'\n","  },\n","  optimizer='adam',\n","  metrics={\n","      'detection_output': ['accuracy'],\n","      'identification_output': ['accuracy'],\n","      'isolation_output': ['accuracy']\n","  }\n",")\n","\n","print(model.summary())\n","\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit(X_train_heads,\n","         [y_train_detection, y_train_identification, y_train_isolation],\n","         epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","\n","# 3.4 model test\n","y_pred_detection, y_pred_identification, y_pred_isolation =\\\n","model.predict(X_test_heads)\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection = (y_pred_detection > 0.5).astype(int).reshape(-1)\n","y_pred_identification = (y_pred_identification > 0.5).astype(int)\n","y_pred_isolation = (y_pred_isolation > 0.5).astype(int)\n","\n","\n","# 3.5 print results for each column\n","training_time = end_time - start_time\n","print(f\"Training Time: {training_time:.1f}\")\n","\n","\n","# Calculate metrics for detection\n","accuracy_det = accuracy_score(y_test_detection, y_pred_detection)\n","precision_det = precision_score(y_test_detection, y_pred_detection)\n","recall_det = recall_score(y_test_detection, y_pred_detection)\n","f1_det = f1_score(y_test_detection, y_pred_detection)\n","\n","# Calculate accuracy for identification\n","accuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\n","precision_iden = precision_score(y_test_identification, y_pred_identification, average=average_approach)\n","recall_iden = recall_score(y_test_identification, y_pred_identification, average=average_approach)\n","f1_iden = f1_score(y_test_identification, y_pred_identification, average=average_approach)\n","\n","# Calculate accuracy for isolation\n","accuracy_iso = accuracy_score(y_test_isolation, y_pred_isolation)\n","precision_iso = precision_score(y_test_isolation, y_pred_isolation, average=average_approach)\n","recall_iso = recall_score(y_test_isolation, y_pred_isolation, average=average_approach)\n","f1_iso = f1_score(y_test_isolation, y_pred_isolation, average=average_approach)\n","\n","\n","# Print results\n","print('Detection:')\n","print(f'    Accuracy: {accuracy_det:.3f}')\n","print(f'    Precision: {precision_det:.3f}')\n","print(f'    Recall: {recall_det:.3f}')\n","print(f'    F1-score: {f1_det:.3f}')\n","\n","print('Identification:')\n","print(f'    Accuracy: {accuracy_iden:.3f}')\n","print(f'    Precision: {precision_iden:.3f}')\n","print(f'    Recall: {recall_iden:.3f}')\n","print(f'    F1-score: {f1_iden:.3f}')\n","\n","print('Isolation:')\n","print(f'    Accuracy: {accuracy_iso:.3f}')\n","print(f'    Precision: {precision_iso:.3f}')\n","print(f'    Recall: {recall_iso:.3f}')\n","print(f'    F1-score: {f1_iso:.3f}')\n","\n","# print('Classification Report:')\n","# print(classification_report(y_test_detection, y_pred_detection))\n","# print(classification_report(y_test_identification, y_pred_identification))\n","# print(classification_report(y_test_isolation, y_pred_isolation))"],"metadata":{"id":"ckL-2macd469"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["v2 (update for 3-5 quads)"],"metadata":{"id":"P0siaaWLnGLS"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive\n","import time\n","\n","# parameters\n","scenario_length = 1000\n","num_attack_types = 3 + 1\n","num_attack_targets = 10 + 1\n","num_quad_features = 10\n","\n","num_quad = 5\n","num_scenarios = 10\n","\n","# hyper-parameter\n","seq_len = 40\n","seq_overlap = seq_len - 1\n","epoch_val = 5\n","batch_size_val = 128\n","\n","# 1 data preprocessing\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/My Drive/code/dataset/network/dataset.csv'\n","data = pd.read_csv(dataset_path)\n","\n","# drop time\n","data = data.drop(columns=['time'])\n","\n","# remove other quads data\n","if num_quad == 2:\n","  data = data.iloc[:, list(range(20)) + list(range(50, 56))]\n","if num_quad == 3:\n","  data = data.iloc[:, list(range(30)) + list(range(50, 59))]\n","if num_quad == 4:\n","  data = data.iloc[:, list(range(40)) + list(range(50, 62))]\n","if num_quad == 5:\n","  data = data.iloc[:, list(range(50)) + list(range(50, 65))]\n","\n","# 1.1 normalization\n","if num_quad == 2:\n","  labels = data[data.columns[20:26]]\n","  data.drop(columns=data.columns[20:26], inplace=True)\n","if num_quad == 3:\n","  labels = data[data.columns[30:39]]\n","  data.drop(columns=data.columns[30:39], inplace=True)\n","if num_quad == 4:\n","  labels = data[data.columns[40:52]]\n","  data.drop(columns=data.columns[40:52], inplace=True)\n","if num_quad == 5:\n","  labels = data[data.columns[50:65]]\n","  data.drop(columns=data.columns[50:65], inplace=True)\n","\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","if num_quad == 2:\n","  y_train_detection_1 = X_train[:, -1, -6]\n","  y_train_identification_1 = X_train[:, -1, -5]\n","  y_train_isolation_1 = X_train[:, -1, -4]\n","  y_train_detection_2 = X_train[:, -1, -3]\n","  y_train_identification_2 = X_train[:, -1, -2]\n","  y_train_isolation_2 = X_train[:, -1, -1]\n","  X_train = X_train[:, :, :-6]\n","\n","  y_test_detection_1 = X_test[:, -1, -6]\n","  y_test_identification_1 = X_test[:, -1, -5]\n","  y_test_isolation_1 = X_test[:, -1, -4]\n","  y_test_detection_2 = X_test[:, -1, -3]\n","  y_test_identification_2 = X_test[:, -1, -2]\n","  y_test_isolation_2 = X_test[:, -1, -1]\n","  X_test = X_test[:, :, :-6]\n","\n","if num_quad == 3:\n","  y_train_detection_1 = X_train[:, -1, -9]\n","  y_train_identification_1 = X_train[:, -1, -8]\n","  y_train_isolation_1 = X_train[:, -1, -7]\n","  y_train_detection_2 = X_train[:, -1, -6]\n","  y_train_identification_2 = X_train[:, -1, -5]\n","  y_train_isolation_2 = X_train[:, -1, -4]\n","  y_train_detection_3 = X_train[:, -1, -3]\n","  y_train_identification_3 = X_train[:, -1, -2]\n","  y_train_isolation_3 = X_train[:, -1, -1]\n","  X_train = X_train[:, :, :-9]\n","\n","  y_test_detection_1 = X_test[:, -1, -9]\n","  y_test_identification_1 = X_test[:, -1, -8]\n","  y_test_isolation_1 = X_test[:, -1, -7]\n","  y_test_detection_2 = X_test[:, -1, -6]\n","  y_test_identification_2 = X_test[:, -1, -5]\n","  y_test_isolation_2 = X_test[:, -1, -4]\n","  y_test_detection_3 = X_test[:, -1, -3]\n","  y_test_identification_3 = X_test[:, -1, -2]\n","  y_test_isolation_3 = X_test[:, -1, -1]\n","  X_test = X_test[:, :, :-9]\n","\n","if num_quad == 4:\n","  y_train_detection_1 = X_train[:, -1, -12]\n","  y_train_identification_1 = X_train[:, -1, -11]\n","  y_train_isolation_1 = X_train[:, -1, -10]\n","  y_train_detection_2 = X_train[:, -1, -9]\n","  y_train_identification_2 = X_train[:, -1, -8]\n","  y_train_isolation_2 = X_train[:, -1, -7]\n","  y_train_detection_3 = X_train[:, -1, -6]\n","  y_train_identification_3 = X_train[:, -1, -5]\n","  y_train_isolation_3 = X_train[:, -1, -4]\n","  y_train_detection_4 = X_train[:, -1, -3]\n","  y_train_identification_4 = X_train[:, -1, -2]\n","  y_train_isolation_4 = X_train[:, -1, -1]\n","  X_train = X_train[:, :, :-12]\n","\n","  y_test_detection_1 = X_test[:, -1, -12]\n","  y_test_identification_1 = X_test[:, -1, -11]\n","  y_test_isolation_1 = X_test[:, -1, -10]\n","  y_test_detection_2 = X_test[:, -1, -9]\n","  y_test_identification_2 = X_test[:, -1, -8]\n","  y_test_isolation_2 = X_test[:, -1, -7]\n","  y_test_detection_3 = X_test[:, -1, -6]\n","  y_test_identification_3 = X_test[:, -1, -5]\n","  y_test_isolation_3 = X_test[:, -1, -4]\n","  y_test_detection_4 = X_test[:, -1, -3]\n","  y_test_identification_4 = X_test[:, -1, -2]\n","  y_test_isolation_4 = X_test[:, -1, -1]\n","  X_test = X_test[:, :, :-12]\n","\n","if num_quad == 5:\n","  y_train_detection_1 = X_train[:, -1, -15]\n","  y_train_identification_1 = X_train[:, -1, -14]\n","  y_train_isolation_1 = X_train[:, -1, -13]\n","  y_train_detection_2 = X_train[:, -1, -12]\n","  y_train_identification_2 = X_train[:, -1, -11]\n","  y_train_isolation_2 = X_train[:, -1, -10]\n","  y_train_detection_3 = X_train[:, -1, -9]\n","  y_train_identification_3 = X_train[:, -1, -8]\n","  y_train_isolation_3 = X_train[:, -1, -7]\n","  y_train_detection_4 = X_train[:, -1, -6]\n","  y_train_identification_4 = X_train[:, -1, -5]\n","  y_train_isolation_4 = X_train[:, -1, -4]\n","  y_train_detection_5 = X_train[:, -1, -3]\n","  y_train_identification_5 = X_train[:, -1, -2]\n","  y_train_isolation_5 = X_train[:, -1, -1]\n","  X_train = X_train[:, :, :-15]\n","\n","  y_test_detection_1 = X_test[:, -1, -15]\n","  y_test_identification_1 = X_test[:, -1, -14]\n","  y_test_isolation_1 = X_test[:, -1, -13]\n","  y_test_detection_2 = X_test[:, -1, -12]\n","  y_test_identification_2 = X_test[:, -1, -11]\n","  y_test_isolation_2 = X_test[:, -1, -10]\n","  y_test_detection_3 = X_test[:, -1, -9]\n","  y_test_identification_3 = X_test[:, -1, -8]\n","  y_test_isolation_3 = X_test[:, -1, -7]\n","  y_test_detection_4 = X_test[:, -1, -6]\n","  y_test_identification_4 = X_test[:, -1, -5]\n","  y_test_isolation_4 = X_test[:, -1, -4]\n","  y_test_detection_5 = X_test[:, -1, -3]\n","  y_test_identification_5 = X_test[:, -1, -2]\n","  y_test_isolation_5 = X_test[:, -1, -1]\n","  X_test = X_test[:, :, :-15]\n","\n","\n","# Split X_train into seperate part for different input heads for each quadcopter\n","if num_quad == 2:\n","  X_train_head_1 = X_train[:, :, 0:10]\n","  X_train_head_2 = X_train[:, :, 10:20]\n","\n","  X_test_head_1 = X_test[:, :, 0:10]\n","  X_test_head_2 = X_test[:, :, 10:20]\n","\n","if num_quad == 3:\n","  X_train_head_1 = X_train[:, :, 0:10]\n","  X_train_head_2 = X_train[:, :, 10:20]\n","  X_train_head_3 = X_train[:, :, 20:30]\n","\n","  X_test_head_1 = X_test[:, :, 0:10]\n","  X_test_head_2 = X_test[:, :, 10:20]\n","  X_test_head_3 = X_test[:, :, 20:30]\n","\n","if num_quad == 4:\n","  X_train_head_1 = X_train[:, :, 0:10]\n","  X_train_head_2 = X_train[:, :, 10:20]\n","  X_train_head_3 = X_train[:, :, 20:30]\n","  X_train_head_4 = X_train[:, :, 30:40]\n","\n","  X_test_head_1 = X_test[:, :, 0:10]\n","  X_test_head_2 = X_test[:, :, 10:20]\n","  X_test_head_3 = X_test[:, :, 20:30]\n","  X_test_head_4 = X_test[:, :, 30:40]\n","\n","if num_quad == 5:\n","  X_train_head_1 = X_train[:, :, 0:10]\n","  X_train_head_2 = X_train[:, :, 10:20]\n","  X_train_head_3 = X_train[:, :, 20:30]\n","  X_train_head_4 = X_train[:, :, 30:40]\n","  X_train_head_5 = X_train[:, :, 40:50]\n","\n","  X_test_head_1 = X_test[:, :, 0:10]\n","  X_test_head_2 = X_test[:, :, 10:20]\n","  X_test_head_3 = X_test[:, :, 20:30]\n","  X_test_head_4 = X_test[:, :, 30:40]\n","  X_test_head_5 = X_test[:, :, 40:50]\n","\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","if num_quad == 2:\n","  # input\n","  input_1 = Input(shape=(seq_len, 10))\n","  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n","  input_2 = Input(shape=(seq_len, 10))\n","  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n","\n","  # shared\n","  concat = Concatenate()([lstm_1, lstm_2])\n","  shared_lstm = LSTM(64)(concat)\n","\n","  # output\n","  output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","  output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","  output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","  output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","  output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","  output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","\n","  model = Model(inputs=[input_1, input_2], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                                    output_detection_2, output_identification_2, output_isolation_2])\n","\n","if num_quad == 3:\n","  # input\n","  input_1 = Input(shape=(seq_len, 10))\n","  lstm_1 = LSTM(32, return_sequences=True)(input_1)\n","  input_2 = Input(shape=(seq_len, 10))\n","  lstm_2 = LSTM(32, return_sequences=True)(input_2)\n","  input_3 = Input(shape=(seq_len, 10))\n","  lstm_3 = LSTM(32, return_sequences=True)(input_3)\n","\n","  # shared\n","  concat = Concatenate()([lstm_1, lstm_2, lstm_3])\n","  shared_lstm = LSTM(64)(concat)\n","\n","  # output\n","  output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","  output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","  output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","  output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","  output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","  output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","  output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n","  output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n","  output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n","\n","  model = Model(inputs=[input_1, input_2, input_3], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                                             output_detection_2, output_identification_2, output_isolation_2,\n","                                                             output_detection_3, output_identification_3, output_isolation_3])\n","\n","if num_quad == 4:\n","    # input\n","    input_1 = Input(shape=(seq_len, 10))\n","    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n","    input_2 = Input(shape=(seq_len, 10))\n","    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n","    input_3 = Input(shape=(seq_len, 10))\n","    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n","    input_4 = Input(shape=(seq_len, 10))\n","    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n","\n","    # shared\n","    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4])\n","    shared_lstm = LSTM(64)(concat)\n","\n","    # output\n","    output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","    output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","    output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","    output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","    output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","    output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","    output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n","    output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n","    output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n","    output_detection_4 = Dense(1, activation='sigmoid', name='detection_output_4')(shared_lstm)\n","    output_identification_4 = Dense(num_attack_types, activation='softmax', name='identification_output_4')(shared_lstm)\n","    output_isolation_4 = Dense(num_attack_targets, activation='softmax', name='isolation_output_4')(shared_lstm)\n","\n","    model = Model(inputs=[input_1, input_2, input_3, input_4], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                                                      output_detection_2, output_identification_2, output_isolation_2,\n","                                                                      output_detection_3, output_identification_3, output_isolation_3,\n","                                                                      output_detection_4, output_identification_4, output_isolation_4])\n","\n","if num_quad == 5:\n","    # input\n","    input_1 = Input(shape=(seq_len, 10))\n","    lstm_1 = LSTM(32, return_sequences=True)(input_1)\n","    input_2 = Input(shape=(seq_len, 10))\n","    lstm_2 = LSTM(32, return_sequences=True)(input_2)\n","    input_3 = Input(shape=(seq_len, 10))\n","    lstm_3 = LSTM(32, return_sequences=True)(input_3)\n","    input_4 = Input(shape=(seq_len, 10))\n","    lstm_4 = LSTM(32, return_sequences=True)(input_4)\n","    input_5 = Input(shape=(seq_len, 10))\n","    lstm_5 = LSTM(32, return_sequences=True)(input_5)\n","\n","    # shared\n","    concat = Concatenate()([lstm_1, lstm_2, lstm_3, lstm_4, lstm_5])\n","    shared_lstm = LSTM(64)(concat)\n","\n","    # output\n","    output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","    output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","    output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","    output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","    output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","    output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","    output_detection_3 = Dense(1, activation='sigmoid', name='detection_output_3')(shared_lstm)\n","    output_identification_3 = Dense(num_attack_types, activation='softmax', name='identification_output_3')(shared_lstm)\n","    output_isolation_3 = Dense(num_attack_targets, activation='softmax', name='isolation_output_3')(shared_lstm)\n","    output_detection_4 = Dense(1, activation='sigmoid', name='detection_output_4')(shared_lstm)\n","    output_identification_4 = Dense(num_attack_types, activation='softmax', name='identification_output_4')(shared_lstm)\n","    output_isolation_4 = Dense(num_attack_targets, activation='softmax', name='isolation_output_4')(shared_lstm)\n","    output_detection_5 = Dense(1, activation='sigmoid', name='detection_output_5')(shared_lstm)\n","    output_identification_5 = Dense(num_attack_types, activation='softmax', name='identification_output_5')(shared_lstm)\n","    output_isolation_5 = Dense(num_attack_targets, activation='softmax', name='isolation_output_5')(shared_lstm)\n","\n","    model = Model(inputs=[input_1, input_2, input_3, input_4, input_5], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                                                      output_detection_2, output_identification_2, output_isolation_2,\n","                                                                      output_detection_3, output_identification_3, output_isolation_3,\n","                                                                      output_detection_4, output_identification_4, output_isolation_4,\n","                                                                      output_detection_5, output_identification_5, output_isolation_5])\n","\n","\n","# 3.2 model compile\n","if num_quad == 2:\n","  model.compile(\n","      loss={\n","          'detection_output_1': 'binary_crossentropy',\n","          'identification_output_1': 'sparse_categorical_crossentropy',\n","          'isolation_output_1': 'sparse_categorical_crossentropy',\n","          'detection_output_2': 'binary_crossentropy',\n","          'identification_output_2': 'sparse_categorical_crossentropy',\n","          'isolation_output_2': 'sparse_categorical_crossentropy'\n","      },\n","      optimizer='adam',\n","      metrics={\n","          'detection_output_1': ['accuracy'],\n","          'identification_output_1': ['accuracy'],\n","          'isolation_output_1': ['accuracy'],\n","          'detection_output_2': ['accuracy'],\n","          'identification_output_2': ['accuracy'],\n","          'isolation_output_2': ['accuracy']\n","      }\n","  )\n","\n","if num_quad == 3:\n","  model.compile(\n","      loss={\n","          'detection_output_1': 'binary_crossentropy',\n","          'identification_output_1': 'sparse_categorical_crossentropy',\n","          'isolation_output_1': 'sparse_categorical_crossentropy',\n","          'detection_output_2': 'binary_crossentropy',\n","          'identification_output_2': 'sparse_categorical_crossentropy',\n","          'isolation_output_2': 'sparse_categorical_crossentropy',\n","          'detection_output_3': 'binary_crossentropy',\n","          'identification_output_3': 'sparse_categorical_crossentropy',\n","          'isolation_output_3': 'sparse_categorical_crossentropy'\n","      },\n","      optimizer='adam',\n","      metrics={\n","          'detection_output_1': ['accuracy'],\n","          'identification_output_1': ['accuracy'],\n","          'isolation_output_1': ['accuracy'],\n","          'detection_output_2': ['accuracy'],\n","          'identification_output_2': ['accuracy'],\n","          'isolation_output_2': ['accuracy'],\n","          'detection_output_3': ['accuracy'],\n","          'identification_output_3': ['accuracy'],\n","          'isolation_output_3': ['accuracy']\n","      }\n","  )\n","\n","if num_quad == 4:\n","  model.compile(\n","      loss={\n","          'detection_output_1': 'binary_crossentropy',\n","          'identification_output_1': 'sparse_categorical_crossentropy',\n","          'isolation_output_1': 'sparse_categorical_crossentropy',\n","          'detection_output_2': 'binary_crossentropy',\n","          'identification_output_2': 'sparse_categorical_crossentropy',\n","          'isolation_output_2': 'sparse_categorical_crossentropy',\n","          'detection_output_3': 'binary_crossentropy',\n","          'identification_output_3': 'sparse_categorical_crossentropy',\n","          'isolation_output_3': 'sparse_categorical_crossentropy',\n","          'detection_output_4': 'binary_crossentropy',\n","          'identification_output_4': 'sparse_categorical_crossentropy',\n","          'isolation_output_4': 'sparse_categorical_crossentropy'\n","      },\n","      optimizer='adam',\n","      metrics={\n","          'detection_output_1': ['accuracy'],\n","          'identification_output_1': ['accuracy'],\n","          'isolation_output_1': ['accuracy'],\n","          'detection_output_2': ['accuracy'],\n","          'identification_output_2': ['accuracy'],\n","          'isolation_output_2': ['accuracy'],\n","          'detection_output_3': ['accuracy'],\n","          'identification_output_3': ['accuracy'],\n","          'isolation_output_3': ['accuracy'],\n","          'detection_output_4': ['accuracy'],\n","          'identification_output_4': ['accuracy'],\n","          'isolation_output_4': ['accuracy']\n","      }\n","  )\n","\n","if num_quad == 5:\n","  model.compile(\n","      loss={\n","          'detection_output_1': 'binary_crossentropy',\n","          'identification_output_1': 'sparse_categorical_crossentropy',\n","          'isolation_output_1': 'sparse_categorical_crossentropy',\n","          'detection_output_2': 'binary_crossentropy',\n","          'identification_output_2': 'sparse_categorical_crossentropy',\n","          'isolation_output_2': 'sparse_categorical_crossentropy',\n","          'detection_output_3': 'binary_crossentropy',\n","          'identification_output_3': 'sparse_categorical_crossentropy',\n","          'isolation_output_3': 'sparse_categorical_crossentropy',\n","          'detection_output_4': 'binary_crossentropy',\n","          'identification_output_4': 'sparse_categorical_crossentropy',\n","          'isolation_output_4': 'sparse_categorical_crossentropy',\n","          'detection_output_5': 'binary_crossentropy',\n","          'identification_output_5': 'sparse_categorical_crossentropy',\n","          'isolation_output_5': 'sparse_categorical_crossentropy'\n","      },\n","      optimizer='adam',\n","      metrics={\n","          'detection_output_1': ['accuracy'],\n","          'identification_output_1': ['accuracy'],\n","          'isolation_output_1': ['accuracy'],\n","          'detection_output_2': ['accuracy'],\n","          'identification_output_2': ['accuracy'],\n","          'isolation_output_2': ['accuracy'],\n","          'detection_output_3': ['accuracy'],\n","          'identification_output_3': ['accuracy'],\n","          'isolation_output_3': ['accuracy'],\n","          'detection_output_4': ['accuracy'],\n","          'identification_output_4': ['accuracy'],\n","          'isolation_output_4': ['accuracy'],\n","          'detection_output_5': ['accuracy'],\n","          'identification_output_5': ['accuracy'],\n","          'isolation_output_5': ['accuracy']\n","      }\n","  )\n","\n","\n","print(model.summary())\n","\n","\n","# 3.3 model train\n","start_time = time.time()\n","\n","if num_quad == 2:\n","  model.fit([X_train_head_1, X_train_head_2],\n","            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","             y_train_detection_2, y_train_identification_2, y_train_isolation_2],\n","            epochs=epoch_val, batch_size=batch_size_val)\n","\n","if num_quad == 3:\n","  model.fit([X_train_head_1, X_train_head_2, X_train_head_3],\n","            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","             y_train_detection_2, y_train_identification_2, y_train_isolation_2,\n","             y_train_detection_3, y_train_identification_3, y_train_isolation_3],\n","            epochs=epoch_val, batch_size=batch_size_val)\n","\n","if num_quad == 4:\n","  model.fit([X_train_head_1, X_train_head_2, X_train_head_3, X_train_head_4],\n","            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","              y_train_detection_2, y_train_identification_2, y_train_isolation_2,\n","              y_train_detection_3, y_train_identification_3, y_train_isolation_3,\n","              y_train_detection_4, y_train_identification_4, y_train_isolation_4],\n","            epochs=epoch_val, batch_size=batch_size_val)\n","\n","if num_quad == 5:\n","  model.fit([X_train_head_1, X_train_head_2, X_train_head_3, X_train_head_4, X_train_head_5],\n","            [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","              y_train_detection_2, y_train_identification_2, y_train_isolation_2,\n","              y_train_detection_3, y_train_identification_3, y_train_isolation_3,\n","              y_train_detection_4, y_train_identification_4, y_train_isolation_4,\n","              y_train_detection_5, y_train_identification_5, y_train_isolation_5],\n","            epochs=epoch_val, batch_size=batch_size_val)\n","\n","\n","end_time = time.time()\n","\n","\n","# 3.4 model test\n","if num_quad == 2:\n","  y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","  y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2 =\\\n","  model.predict([X_test_head_1, X_test_head_2])\n","\n","if num_quad == 3:\n","  y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","  y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n","  y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3 =\\\n","  model.predict([X_test_head_1, X_test_head_2, X_test_head_3])\n","\n","if num_quad == 4:\n","    y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","    y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n","    y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3, \\\n","    y_pred_detection_4, y_pred_identification_4, y_pred_isolation_4 = \\\n","    model.predict([X_test_head_1, X_test_head_2, X_test_head_3, X_test_head_4])\n","\n","if num_quad == 5:\n","    y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","    y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2, \\\n","    y_pred_detection_3, y_pred_identification_3, y_pred_isolation_3, \\\n","    y_pred_detection_4, y_pred_identification_4, y_pred_isolation_4, \\\n","    y_pred_detection_5, y_pred_identification_5, y_pred_isolation_5 = \\\n","    model.predict([X_test_head_1, X_test_head_2, X_test_head_3, X_test_head_4, X_test_head_5])\n","\n","\n","# Convert predictions for binary and multi-class\n","if num_quad == 2:\n","  y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","  y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","  y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","  y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","  y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","  y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","\n","if num_quad == 3:\n","  y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","  y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","  y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","  y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","  y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","  y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","  y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n","  y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n","  y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n","\n","if num_quad == 4:\n","    y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","    y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","    y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","    y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","    y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n","    y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n","    y_pred_detection_4 = (y_pred_detection_4 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_4 = np.argmax(y_pred_identification_4, axis=1)\n","    y_pred_isolation_4 = np.argmax(y_pred_isolation_4, axis=1)\n","\n","if num_quad == 5:\n","    y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","    y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","    y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","    y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","    y_pred_detection_3 = (y_pred_detection_3 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_3 = np.argmax(y_pred_identification_3, axis=1)\n","    y_pred_isolation_3 = np.argmax(y_pred_isolation_3, axis=1)\n","    y_pred_detection_4 = (y_pred_detection_4 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_4 = np.argmax(y_pred_identification_4, axis=1)\n","    y_pred_isolation_4 = np.argmax(y_pred_isolation_4, axis=1)\n","    y_pred_detection_5 = (y_pred_detection_5 > 0.5).astype(int).reshape(-1)\n","    y_pred_identification_5 = np.argmax(y_pred_identification_5, axis=1)\n","    y_pred_isolation_5 = np.argmax(y_pred_isolation_5, axis=1)\n","\n","# 3.5 print results for each column\n","\n","training_time = end_time - start_time\n","print(f\"Training Time: {training_time:.1f}\")\n","\n","\n","for quad in range(1, num_quad+1):\n","    # Retrieve the y_test and y_pred variables dynamically based on the quad number\n","    y_test_detection = eval(f'y_test_detection_{quad}')\n","    y_pred_detection = eval(f'y_pred_detection_{quad}')\n","    y_test_identification = eval(f'y_test_identification_{quad}')\n","    y_pred_identification = eval(f'y_pred_identification_{quad}')\n","    y_test_isolation = eval(f'y_test_isolation_{quad}')\n","    y_pred_isolation = eval(f'y_pred_isolation_{quad}')\n","\n","    # Calculate metrics for detection\n","    accuracy = accuracy_score(y_test_detection, y_pred_detection)\n","    precision = precision_score(y_test_detection, y_pred_detection)\n","    recall = recall_score(y_test_detection, y_pred_detection)\n","    f1 = f1_score(y_test_detection, y_pred_detection)\n","\n","    # Calculate accuracy for identification and isolation\n","    accuracy_iden = accuracy_score(y_test_identification, y_pred_identification)\n","    accuracy_isol = accuracy_score(y_test_isolation, y_pred_isolation)\n","\n","    # Print results\n","    print(f'Quad {quad}:')\n","    print(' Detection:')\n","    print(f'    Accuracy: {accuracy:.3f}')\n","    print(f'    Precision: {precision:.3f}')\n","    print(f'    Recall: {recall:.3f}')\n","    print(f'    F1-score: {f1:.3f}')\n","\n","    print(' Identification:')\n","    print(f'    Accuracy: {accuracy_iden:.3f}')\n","\n","    print(' Localization:')\n","    print(f'    Accuracy: {accuracy_isol:.3f}')\n","\n","    print(' Classification Report:')\n","    print(classification_report(y_test_detection, y_pred_detection))\n","    print(classification_report(y_test_identification, y_pred_identification))\n","    print(classification_report(y_test_isolation, y_pred_isolation))\n"],"metadata":{"id":"HQKvLCXZnF9j"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["v2 (get DS from drive, update to final version, 2 quads, ability to select between all data or only sensors)"],"metadata":{"id":"pCfIz0pZTklf"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive\n","import time\n","\n","\n","# parameters\n","num_features = 20\n","quad_num_features = 10\n","scenario_length = 1000\n","num_attack_types = 3 + 1\n","num_attack_targets = 10 + 1\n","num_quad = 2\n","\n","num_scenarios = 20\n","\n","# hyper-parameter\n","seq_len = 40\n","seq_overlap = seq_len - 1\n","lstm_blocks = 128\n","epoch_val = 50\n","batch_size_val = 128\n","\n","# 1 data preprocessing\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/My Drive/code/dataset/network/dataset.csv'\n","data = pd.read_csv(dataset_path)\n","\n","# remove other quads data\n","data = data.loc[:, data.columns[:21].tolist() + data.columns[51:57].tolist()]\n","\n","\n","# 1.1 normalization\n","labels = data[['label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2']]\n","data = data.drop(columns=['time', 'label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","for s in range(0, num_scenarios):\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train_detection_1 = X_train[:, -1, -6]\n","y_train_identification_1 = X_train[:, -1, -5]\n","y_train_isolation_1 = X_train[:, -1, -4]\n","y_train_detection_2 = X_train[:, -1, -3]\n","y_train_identification_2 = X_train[:, -1, -2]\n","y_train_isolation_2 = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-6]\n","\n","y_test_detection_1 = X_test[:, -1, -6]\n","y_test_identification_1 = X_test[:, -1, -5]\n","y_test_isolation_1 = X_test[:, -1, -4]\n","y_test_detection_2 = X_test[:, -1, -3]\n","y_test_identification_2 = X_test[:, -1, -2]\n","y_test_isolation_2 = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-6]\n","\n","# Split X_train into two parts: first half and second half\n","# set if both actuator and sensor data will be used or only sensor\n","X_train_head_1 = X_train[:, :, :10]\n","X_train_head_2 = X_train[:, :, 10:16]\n","\n","X_test_head_1 = X_test[:, :, :10]\n","X_test_head_2 = X_test[:, :, 10:16]\n","\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","# input\n","input_1 = Input(shape=(seq_len, quad_num_features))\n","lstm_1 = LSTM(32, return_sequences=True)(input_1)\n","input_2 = Input(shape=(seq_len, 6))\n","lstm_2 = LSTM(32, return_sequences=True)(input_2)\n","\n","# shared\n","concat = Concatenate()([lstm_1, lstm_2])\n","shared_lstm = LSTM(64)(concat)\n","\n","# output\n","output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","\n","model = Model(inputs=[input_1, input_2], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                           output_detection_2, output_identification_2, output_isolation_2])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output_1': 'binary_crossentropy',\n","        'identification_output_1': 'sparse_categorical_crossentropy',\n","        'isolation_output_1': 'sparse_categorical_crossentropy',\n","        'detection_output_2': 'binary_crossentropy',\n","        'identification_output_2': 'sparse_categorical_crossentropy',\n","        'isolation_output_2': 'sparse_categorical_crossentropy'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output_1': ['accuracy'],\n","        'identification_output_1': ['accuracy'],\n","        'isolation_output_1': ['accuracy'],\n","        'detection_output_2': ['accuracy'],\n","        'identification_output_2': ['accuracy'],\n","        'isolation_output_2': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","start_time = time.time()\n","model.fit([X_train_head_1, X_train_head_2], [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","                    y_train_detection_2, y_train_identification_2, y_train_isolation_2],\n","                    epochs=epoch_val, batch_size=batch_size_val)\n","end_time = time.time()\n","\n","\n","# 3.4 model test\n","y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2 = model.predict([X_test_head_1, X_test_head_2])\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","\n","# 3.5 print results for each column\n","\n","training_time = end_time - start_time\n","\n","# quad 1\n","accuracy = accuracy_score(y_test_detection_1, y_pred_detection_1)\n","precision = precision_score(y_test_detection_1, y_pred_detection_1)\n","recall = recall_score(y_test_detection_1, y_pred_detection_1)\n","f1 = f1_score(y_test_detection_1, y_pred_detection_1)\n","accuracy_iden = accuracy_score(y_test_identification_1, y_pred_identification_1)\n","accuracy_isol = accuracy_score(y_test_isolation_1, y_pred_isolation_1)\n","\n","print(f\"Training Time: {training_time:.1f}\")\n","\n","print('Quad 1:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_iden:.3f}')\n","\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_isol:.3f}')\n","\n","print(' Classification Report: ')\n","print(classification_report(y_test_detection_1, y_pred_detection_1))\n","print(classification_report(y_test_identification_1, y_pred_identification_1))\n","print(classification_report(y_test_isolation_1, y_pred_isolation_1))\n","\n","# quad 2\n","accuracy = accuracy_score(y_test_detection_2, y_pred_detection_2)\n","precision = precision_score(y_test_detection_2, y_pred_detection_2)\n","recall = recall_score(y_test_detection_2, y_pred_detection_2)\n","f1 = f1_score(y_test_detection_2, y_pred_detection_2)\n","accuracy_iden = accuracy_score(y_test_identification_2, y_pred_identification_2)\n","accuracy_isol = accuracy_score(y_test_isolation_2, y_pred_isolation_2)\n","\n","print('Quad 2:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","# 3.6 print results for identification\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_iden:.3f}')\n","\n","# 3.7 print results for localization\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_isol:.3f}')\n","\n","print(' Classification Report: ')\n","print(classification_report(y_test_detection_2, y_pred_detection_2))\n","print(classification_report(y_test_identification_2, y_pred_identification_2))\n","print(classification_report(y_test_isolation_2, y_pred_isolation_2))"],"metadata":{"id":"9M5heVS8TkV0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["multi input - multi output LSTM"],"metadata":{"id":"CBoVUBnMmYPL"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"TRCHjHVkmVAM"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","from numpy import array\n","from tensorflow.keras.models import Sequential, Model\n","from tensorflow.keras.layers import LSTM, Dense, Input, Concatenate\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.preprocessing import StandardScaler\n","from google.colab import drive\n","\n","\n","# parameters\n","num_features = 20\n","quad_num_features = 10\n","num_scenarios = 6\n","scenario_length = 1000\n","attack_type = 0 \t\t# 0: all, 1: DoS, 2: FDI, 3: Replay\n","num_attack_types = 3 + 1\n","num_attack_targets = 6 + 1\n","num_quad = 2\n","\n","# hyper-parameter\n","seq_len = 20\n","seq_overlap = seq_len - 1\n","lstm_blocks = 64\n","epoch_val = 20\n","batch_size_val = 4\n","\n","# 1 data preprocessing\n","drive.mount('/content/drive')\n","dataset_path = '/content/drive/My Drive/code/dataset/network/dataset.csv'\n","data = pd.read_csv(dataset_path)\n","\n","# 1.1 normalization\n","labels = data[['label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2']]\n","data = data.drop(columns=['time', 'label_1', 'type_1', 'target_1', 'label_2', 'type_2', 'target_2'])\n","scaler = StandardScaler()\n","data_normalized = scaler.fit_transform(data)\n","data_normalized = pd.DataFrame(data_normalized, columns=data.columns)\n","data_normalized = pd.concat([data_normalized, labels], axis=1)\n","\n","# 1.2 sequence generation\n","sequences = []\n","step_len = seq_len - seq_overlap\n","\n","if attack_type == 0:\n","    scenario_range = range(0, 6)\n","elif attack_type == 1:\n","    scenario_range = range(0, 2)\n","elif attack_type == 2:\n","    scenario_range = range(2, 4)\n","elif attack_type == 3:\n","    scenario_range = range(4, 6)\n","\n","for s in scenario_range:\n","    scenario_start = s * scenario_length\n","    for i in range(scenario_start, scenario_start + scenario_length - seq_len, step_len):\n","        sequence = data_normalized[i:i + seq_len]\n","        sequences.append(sequence)\n","data_sequences = array(sequences)\n","\n","# 2 data preperation\n","# 2.1 train-test split\n","data_reshaped = data_sequences.reshape(data_sequences.shape[0], -1)\n","X_train, X_test = train_test_split(data_reshaped, test_size=0.25, random_state=42)\n","X_train = X_train.reshape(X_train.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","X_test = X_test.reshape(X_test.shape[0], data_sequences.shape[1], data_sequences.shape[2])\n","\n","# 2.2 reshape data for LSTM network\n","y_train_detection_1 = X_train[:, -1, -6]\n","y_train_identification_1 = X_train[:, -1, -5]\n","y_train_isolation_1 = X_train[:, -1, -4]\n","y_train_detection_2 = X_train[:, -1, -3]\n","y_train_identification_2 = X_train[:, -1, -2]\n","y_train_isolation_2 = X_train[:, -1, -1]\n","X_train = X_train[:, :, :-6]\n","\n","y_test_detection_1 = X_test[:, -1, -6]\n","y_test_identification_1 = X_test[:, -1, -5]\n","y_test_isolation_1 = X_test[:, -1, -4]\n","y_test_detection_2 = X_test[:, -1, -3]\n","y_test_identification_2 = X_test[:, -1, -2]\n","y_test_isolation_2 = X_test[:, -1, -1]\n","X_test = X_test[:, :, :-6]\n","\n","# Split X_train into two parts: first half and second half\n","X_train_head_1 = X_train[:, :, :10]\n","X_train_head_2 = X_train[:, :, 10:]\n","X_test_head_1 = X_test[:, :, :10]\n","X_test_head_2 = X_test[:, :, 10:]\n","\n","# 3. model creation\n","# 3.1 model archiecture\n","input_own = Input(shape=(seq_len, quad_num_features))\n","lstm_own = LSTM(16, return_sequences=True)(input_own)\n","input_neighbor = Input(shape=(seq_len, quad_num_features))\n","lstm_neighbor = LSTM(16, return_sequences=True)(input_neighbor)\n","\n","concat = Concatenate()([lstm_own, lstm_neighbor])\n","shared_lstm = LSTM(16)(concat)\n","\n","output_detection_1 = Dense(1, activation='sigmoid', name='detection_output_1')(shared_lstm)\n","output_identification_1 = Dense(num_attack_types, activation='softmax', name='identification_output_1')(shared_lstm)\n","output_isolation_1 = Dense(num_attack_targets, activation='softmax', name='isolation_output_1')(shared_lstm)\n","output_detection_2 = Dense(1, activation='sigmoid', name='detection_output_2')(shared_lstm)\n","output_identification_2 = Dense(num_attack_types, activation='softmax', name='identification_output_2')(shared_lstm)\n","output_isolation_2 = Dense(num_attack_targets, activation='softmax', name='isolation_output_2')(shared_lstm)\n","\n","model = Model(inputs=[input_own, input_neighbor], outputs=[output_detection_1, output_identification_1, output_isolation_1,\n","                                           output_detection_2, output_identification_2, output_isolation_2])\n","\n","# 3.2 model compile\n","model.compile(\n","    loss={\n","        'detection_output_1': 'binary_crossentropy',\n","        'identification_output_1': 'sparse_categorical_crossentropy',\n","        'isolation_output_1': 'sparse_categorical_crossentropy',\n","        'detection_output_2': 'binary_crossentropy',\n","        'identification_output_2': 'sparse_categorical_crossentropy',\n","        'isolation_output_2': 'sparse_categorical_crossentropy'\n","    },\n","    optimizer='adam',\n","    metrics={\n","        'detection_output_1': ['accuracy'],\n","        'identification_output_1': ['accuracy'],\n","        'isolation_output_1': ['accuracy'],\n","        'detection_output_2': ['accuracy'],\n","        'identification_output_2': ['accuracy'],\n","        'isolation_output_2': ['accuracy']\n","    }\n",")\n","print(model.summary())\n","\n","# 3.3 model train\n","model.fit([X_train_head_1, X_train_head_2], [y_train_detection_1, y_train_identification_1, y_train_isolation_1,\n","                    y_train_detection_2, y_train_identification_2, y_train_isolation_2],\n","          epochs=epoch_val, batch_size=batch_size_val)\n","\n","# 3.4 model test\n","y_pred_detection_1, y_pred_identification_1, y_pred_isolation_1, \\\n","y_pred_detection_2, y_pred_identification_2, y_pred_isolation_2 = model.predict([X_test_head_1, X_test_head_2])\n","\n","# Convert predictions for binary and multi-class\n","y_pred_detection_1 = (y_pred_detection_1 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_1 = np.argmax(y_pred_identification_1, axis=1)\n","y_pred_isolation_1 = np.argmax(y_pred_isolation_1, axis=1)\n","y_pred_detection_2 = (y_pred_detection_2 > 0.5).astype(int).reshape(-1)\n","y_pred_identification_2 = np.argmax(y_pred_identification_2, axis=1)\n","y_pred_isolation_2 = np.argmax(y_pred_isolation_2, axis=1)\n","\n","# 3.5 print results for each column\n","\n","# quad 1\n","accuracy = accuracy_score(y_test_detection_1, y_pred_detection_1)\n","precision = precision_score(y_test_detection_1, y_pred_detection_1)\n","recall = recall_score(y_test_detection_1, y_pred_detection_1)\n","f1 = f1_score(y_test_detection_1, y_pred_detection_1)\n","\n","print('Quad 1:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification_1, y_pred_identification_1)\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_id:.3f}')\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation_1, y_pred_isolation_1)\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_iso:.3f}')\n","\n","\n","# quad 2\n","accuracy = accuracy_score(y_test_detection_2, y_pred_detection_2)\n","precision = precision_score(y_test_detection_2, y_pred_detection_2)\n","recall = recall_score(y_test_detection_2, y_pred_detection_2)\n","f1 = f1_score(y_test_detection_2, y_pred_detection_2)\n","\n","print('Quad 2:')\n","print(' Detection:')\n","print(f'    Accuracy: {accuracy:.3f}')\n","print(f'    Precision: {precision:.3f}')\n","print(f'    Recall: {recall:.3f}')\n","print(f'    F1-score: {f1:.3f}')\n","\n","# 3.6 print results for identification\n","accuracy_id = accuracy_score(y_test_identification_2, y_pred_identification_2)\n","print(' Identification:')\n","print(f'    Accuracy: {accuracy_id:.3f}')\n","\n","# 3.7 print results for localization\n","accuracy_iso = accuracy_score(y_test_isolation_2, y_pred_isolation_2)\n","print(' Localization:')\n","print(f'    Accuracy: {accuracy_iso:.3f}')"]}]}